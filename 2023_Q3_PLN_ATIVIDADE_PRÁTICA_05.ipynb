{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiegoGuerra00/pln/blob/main/2023_Q3_PLN_ATIVIDADE_PR%C3%81TICA_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2023.Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **ATIVIDADE PRÁTICA 05 [LangChain + Grandes Modelos de Linguagem + API]**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk0nHKabBT-"
      },
      "source": [
        "A **ATIVIDADE PRÁTICA 05** deve ser feita utilizando o **Google Colab** com uma conta sua vinculada ao Gmail. O link do seu notebook, armazenado no Google Drive, além do link de um repositório no GitHub e os principais resultados da atividade, devem ser enviados usando o seguinte formulário:\n",
        "\n",
        "> https://forms.gle/C1oUi1FKTZ4W9fNdA\n",
        "\n",
        "\n",
        "**IMPORTANTE**: A submissão deve ser feita até o dia **10/12 (domingo)** APENAS POR UM INTEGRANTE DA EQUIPE, até às 23h59. Por favor, lembre-se de dar permissão de ACESSO IRRESTRITO para o professor da disciplina de PLN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01:**\n",
        "\n",
        "`Por favor, informe o seu nome completo e RA:` Diego Guerra / RA: 11201810534\n",
        "\n",
        "**Integrante 02:**\n",
        "\n",
        "`Por favor, informe o seu nome completo e RA:` Isolda Costa / RA: 21053014\n",
        "\n",
        "**Integrante 03:**\n",
        "\n",
        "`Por favor, informe o seu nome completo e RA:` Luis Gustavo Campos / RA: 11201811265"
      ],
      "metadata": {
        "id": "tnIArN0QY-Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GRANDE MODELO DE LINGUAGEM (*Large Language Model - LLM*)**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "VbYD2mw8y4CN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cada equipe deve selecionar um Grande Modelo de Linguagem (*Large Language Model - LMM*). Preferencialmente, usar um modelo gratuito. Cada modelo pode ser escolhido por até 4 equipes.\n",
        "\n",
        ">\n",
        "\n",
        "Uma lista de LLMs está disponível em:\n",
        "\n",
        "> https://integrations.langchain.com/llms\n",
        "> https://python.langchain.com/docs/integrations/llms/"
      ],
      "metadata": {
        "id": "_UlblxFxzDV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelos da Hugging Face:**\n",
        "\n",
        "* Mistral Base: modelo promissor.\n",
        "\n",
        "> https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\n",
        "\n",
        "* Mistral Quantizado: mais leve. Pode ser um pouco mais difícil de configurar, mas deve ocupar menos memória.\n",
        "\n",
        "> https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF\n",
        "\n",
        "* Mistral Lite da Amazon: pode ter desempenho melhor.\n",
        "\n",
        "> https://huggingface.co/amazon/MistralLite\n",
        "\n",
        "* Llama 2 7B: modelo da Meta melhorado.\n",
        "\n",
        "> https://huggingface.co/meta-llama/Llama-2-7b-chat-hf\n",
        "\n",
        "* Llama 2 7b 32k: contexto maior pelo mesmo tamanho.\n",
        "\n",
        "> https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct\n",
        "\n",
        "* Galactica: para artigos científicos\n",
        "\n",
        "> https://huggingface.co/facebook/galactica-6.7b\n",
        "\n",
        "* Alpaca: alternativo ao Llama\n",
        "\n",
        "> https://huggingface.co/chavinlo/alpaca-native\n",
        "\n",
        "> https://huggingface.co/spaces/tloen/alpaca-lora"
      ],
      "metadata": {
        "id": "GVpiVhzn3QqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lista de Modelos Interessantes:**\n",
        "\n",
        "> https://www.kdnuggets.com/2023/04/8-opensource-alternative-chatgpt-bard.html\n",
        "\n",
        "* Vicuna:\n",
        "> https://huggingface.co/lmsys/vicuna-7b-v1.5-16k\n",
        "\n",
        "* Openchat kit:\n",
        "> https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B\n",
        "\n",
        "* Meta OPT:\n",
        "> https://huggingface.co/facebook/opt-1.3b\n",
        "\n",
        "* Google Flan:\n",
        "> https://huggingface.co/google/flan-t5-base"
      ],
      "metadata": {
        "id": "WRuAiSr05Ayt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**APIs:**\n",
        "\n",
        "* GPT4ALL: tenta ser um chatGPT aberto\n",
        "> https://python.langchain.com/docs/integrations/llms/gpt4all\n",
        "\n",
        "* YandexGPT: da empresa russa que criou um modelo de *Machine Learning* clássico muito bom, o CatBoost.\n",
        "> https://python.langchain.com/docs/integrations/llms/yandex\n",
        "\n",
        "* Anthropic: empresa forte concorrente da OpenAi.\n",
        "> https://python.langchain.com/docs/integrations/chat/anthropic\n",
        "\n",
        "* Gorilla: pipeline para geração de código\n",
        " > https://www.kdnuggets.com/2023/06/meet-gorilla-uc-berkeley-microsoft-apiaugmented-llm-outperforms-gpt4-chatgpt-claude.html"
      ],
      "metadata": {
        "id": "5Q3mhqda5WP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE**: todo esse levantamento e comentários foram feitos pelo aluno  **Bruno Sanches Rodrigues**."
      ],
      "metadata": {
        "id": "DO6XMjHx58u9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por favor, informe os dados do LLM selecionada:\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "**LLM**: Petals\n",
        "\n",
        ">\n",
        "\n",
        "**Link para a documentação oficial**:\n",
        "https://python.langchain.com/docs/integrations/llms/petals\n",
        ">\n",
        "\n",
        "\n",
        "**Site oficial (GitHub)**: https://github.com/bigscience-workshop/petals"
      ],
      "metadata": {
        "id": "a6AkE6iW0c3o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE**: não pode ser o modelo da `OpenAI`."
      ],
      "metadata": {
        "id": "A2oo8GtK0xSO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **API**\n",
        "---"
      ],
      "metadata": {
        "id": "6yExhaebs-nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por favor, informe os dados da API selecionada:\n",
        "\n",
        "**API**: New York Times\n",
        "\n",
        "**Site oficial**: https://www.nytimes.com/international/\n",
        "\n",
        "**Link para a documentação oficial**: https://developer.nytimes.com/apis\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DjJM_qhEZRy6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE**: não é necessário usar a mesma **API** da `ATIVIDADE PRÁTICA 03`. Cada **API** pode ser usada por até 4 equipes."
      ],
      "metadata": {
        "id": "bTODq98Myt_u"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRIÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementar um `notebook` no `Google Colab` que faça uso do framework **`LangChain`** (obrigatório) e de um **LLM** aplicando, no mínimo, uma técnica de PLN. A técnica pode ser aplicada em qualquer córpus. Também é obrigatório usar uma **API** da `ATIVIDADE PRÁTICA 03`. A **API** pode ser usada tanto para obter os dados quanto para disponibilizar os resultados.\n",
        "\n",
        "O **LLM** e a **API** selecionados devem ser informados na seguinte planilha:\n",
        "\n",
        "> https://docs.google.com/spreadsheets/d/1cOL7zVNffqmliuv23zFm1UJjhEXTdp1Zm5EyAJmhiKg/edit?usp=sharing\n",
        "\n",
        ">\n",
        "As seguintes técnicas de PLN podem ser usadas:\n",
        "\n",
        "*   Correção Gramatical\n",
        "*   Classificação de Textos\n",
        "*   Análise de Sentimentos\n",
        "*   Detecção de Emoções\n",
        "*   Extração de Palavras-chave\n",
        "*   Tradução de Textos\n",
        "*   Sumarização de Textos\n",
        "*   Similaridade de Textos\n",
        "*   Reconhecimento de Entidades Nomeadas\n",
        "*   Sistemas de Perguntas e Respostas\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Lista de APIs:**\n",
        "\n",
        "\n",
        "* YouTube\n",
        "* LinkedIn\n",
        "* Twitter (X)\n",
        "* Facebook\n",
        "* Instagram\n",
        "* Medium\n",
        "* Reddit\n",
        "* TikTok\n",
        "* GitHub\n",
        "* Pinterest\n",
        "* Telegram\n",
        "* Dados financeiros\n",
        "* Notícias\n",
        "* Mercado de Ações\n",
        "* Dados financeiros\n",
        "* SMS\n",
        "* OpenAlex\n",
        "* Whisper (OpenAI)\n",
        "* Discord\n",
        "* Slack\n",
        "* Chuck Norris Jokes\n",
        "* Wikipedia\n",
        "* Last.fm\n",
        "* New York Times\n",
        "* Nasdaq Data Link\n",
        "* Yahoo! Finance\n",
        "* Twilio SendGrid Mail Send\n",
        "* Spotify\n",
        "* Awesome API\n",
        "* Google Books API\n",
        "* Mercado Livre API\n",
        "\n",
        ">\n",
        "\n",
        "**PLANILHA DA ATIVIDADE PRÁTICA 03:**\n",
        "\n",
        "> https://docs.google.com/spreadsheets/d/1-Q1szJ3UmoE2_3LtcRQyqid5fPIcnpsR3XAPnoxLj2o/edit?usp=sharing\n",
        "\n",
        "\n",
        "**IMPORTANTE:** É obrigatório usar o e-mail da UFABC.\n"
      ],
      "metadata": {
        "id": "fXTwkiiGs2BV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CRITÉRIOS DE AVALIAÇÃO**\n",
        "---\n"
      ],
      "metadata": {
        "id": "gWsBYQNtxmum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Serão considerados como critérios de avaliação os segunintes pontos:\n",
        "\n",
        "* Uso do framework **`LangChain`**.\n",
        "\n",
        "* Escolha e uso de um **LLM**.\n",
        "\n",
        "* Escolha e uso de uma **API**\n",
        "\n",
        "* Criatividade no uso do framework **`LangChain`** em conjunto com o **LLM** e a **API**.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5iHdx4BXYruQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE**: todo o código do notebook deve ser executado. Código sem execução não será considerado."
      ],
      "metadata": {
        "id": "LhwdrMp123Xx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPLEMENTAÇÃO**\n",
        "---"
      ],
      "metadata": {
        "id": "nw09lujGvfjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install petals"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYYt1j7xdsa4",
        "outputId": "91201622-8c0f-4c3b-a077-8b441e4d2305"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: petals in /usr/local/lib/python3.10/dist-packages (2.2.0.post1)\n",
            "Requirement already satisfied: torch>=1.12 in /usr/local/lib/python3.10/dist-packages (from petals) (2.1.0+cu118)\n",
            "Requirement already satisfied: bitsandbytes==0.41.1 in /usr/local/lib/python3.10/dist-packages (from petals) (0.41.1)\n",
            "Requirement already satisfied: accelerate>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from petals) (0.25.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from petals) (0.17.3)\n",
            "Requirement already satisfied: tokenizers>=0.13.3 in /usr/local/lib/python3.10/dist-packages (from petals) (0.14.1)\n",
            "Requirement already satisfied: transformers<4.35.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from petals) (4.34.1)\n",
            "Requirement already satisfied: speedtest-cli==2.1.3 in /usr/local/lib/python3.10/dist-packages (from petals) (2.1.3)\n",
            "Requirement already satisfied: pydantic<2.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from petals) (1.10.13)\n",
            "Requirement already satisfied: hivemind==1.1.10.post2 in /usr/local/lib/python3.10/dist-packages (from petals) (1.1.10.post2)\n",
            "Requirement already satisfied: tensor-parallel==1.0.23 in /usr/local/lib/python3.10/dist-packages (from petals) (1.0.23)\n",
            "Requirement already satisfied: humanfriendly in /usr/local/lib/python3.10/dist-packages (from petals) (10.0)\n",
            "Requirement already satisfied: async-timeout>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from petals) (4.0.3)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from petals) (23.2)\n",
            "Requirement already satisfied: sentencepiece>=0.1.99 in /usr/local/lib/python3.10/dist-packages (from petals) (0.1.99)\n",
            "Requirement already satisfied: peft==0.5.0 in /usr/local/lib/python3.10/dist-packages (from petals) (0.5.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from petals) (0.4.1)\n",
            "Requirement already satisfied: Dijkstar>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from petals) (2.6.0)\n",
            "Requirement already satisfied: cpufeature>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from petals) (0.2.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.10.post2->petals) (6.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.10.post2->petals) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.10.post2->petals) (1.11.4)\n",
            "Requirement already satisfied: prefetch-generator>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.10.post2->petals) (1.0.3)\n",
            "Requirement already satisfied: msgpack>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.10.post2->petals) (1.0.7)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.10.post2->petals) (2.4.0)\n",
            "Requirement already satisfied: uvloop>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.10.post2->petals) (0.19.0)\n",
            "Requirement already satisfied: grpcio-tools>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.10.post2->petals) (1.60.0)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.10.post2->petals) (4.25.1)\n",
            "Requirement already satisfied: configargparse>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.10.post2->petals) (1.7)\n",
            "Requirement already satisfied: multiaddr>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.10.post2->petals) (0.0.9)\n",
            "Requirement already satisfied: pymultihash>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.10.post2->petals) (0.8.2)\n",
            "Requirement already satisfied: cryptography>=3.4.6 in /usr/local/lib/python3.10/dist-packages (from hivemind==1.1.10.post2->petals) (41.0.7)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.5.0->petals) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft==0.5.0->petals) (4.66.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from Dijkstar>=2.6.0->petals) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.1->petals) (3.13.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.1->petals) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.1->petals) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.1->petals) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->petals) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->petals) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->petals) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->petals) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<4.35.0,>=4.32.0->petals) (2023.6.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.4.6->hivemind==1.1.10.post2->petals) (1.16.0)\n",
            "Requirement already satisfied: grpcio>=1.60.0 in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.33.2->hivemind==1.1.10.post2->petals) (1.60.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.33.2->hivemind==1.1.10.post2->petals) (67.7.2)\n",
            "Requirement already satisfied: varint in /usr/local/lib/python3.10/dist-packages (from multiaddr>=0.0.9->hivemind==1.1.10.post2->petals) (1.0.2)\n",
            "Requirement already satisfied: base58 in /usr/local/lib/python3.10/dist-packages (from multiaddr>=0.0.9->hivemind==1.1.10.post2->petals) (2.1.1)\n",
            "Requirement already satisfied: netaddr in /usr/local/lib/python3.10/dist-packages (from multiaddr>=0.0.9->hivemind==1.1.10.post2->petals) (0.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12->petals) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0.0,>=0.11.1->petals) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0.0,>=0.11.1->petals) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0.0,>=0.11.1->petals) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0.0,>=0.11.1->petals) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12->petals) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.4.6->hivemind==1.1.10.post2->petals) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McxPDiPHmsVD",
        "outputId": "f2516373-156d-47ff-b3d6-018d269c3570"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.350)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.2)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.0)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.69)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import Petals\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "z6mcBwovgQGQ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "HUGGINGFACE_API_KEY = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0MUHFa8gY7-",
        "outputId": "45820cb2-ba3b-4fb0-ca43-b116c7dbe628"
      },
      "execution_count": 54,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nyt_api = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmQdPfgxfH2b",
        "outputId": "79b1d73c-9da3-42b4-8dba-589576d01451"
      },
      "execution_count": 55,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HUGGINGFACE_API_KEY\"] = HUGGINGFACE_API_KEY"
      ],
      "metadata": {
        "id": "KBsnbaT7iqyW"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = Petals(model_name=\"petals-team/StableBeluga2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnR-aYQHis_Z",
        "outputId": "43961842-c242-4074-bf05-7130631eb297"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Dec 13 01:08:50.018 [\u001b[1m\u001b[34mINFO\u001b[0m] Make sure you follow the LLaMA's terms of use: https://bit.ly/llama2-license for LLaMA 2, https://bit.ly/llama-license for LLaMA 1\n",
            "Dec 13 01:08:50.021 [\u001b[1m\u001b[34mINFO\u001b[0m] Using DHT prefix: StableBeluga2-hf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, json, random\n",
        "\n",
        "def get_corpus():\n",
        "  url = \"https://api.nytimes.com/svc/search/v2/articlesearch.json?q=&api-key=\" + nyt_api\n",
        "  response = requests.get(url)\n",
        "  articles = json.loads(response.content)\n",
        "\n",
        "  article = articles[\"response\"][\"docs\"][random.randint(0, len(articles[\"response\"][\"docs\"]) - 1)]\n",
        "\n",
        "  text = article[\"snippet\"] + article[\"abstract\"] + article[\"lead_paragraph\"]\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "IYKeGzXLtzSJ"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def REN():\n",
        "  template = \"\"\"TEXTO: {text}\n",
        "  Dado o texto acima você irá realizar o Reconhecimento de Entidades Nomeadas,\n",
        "  retornando as Entidades encontradas no formato de uma Lista do Python\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
        "  llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "  text = get_corpus()\n",
        "\n",
        "  llm_chain.run(text)"
      ],
      "metadata": {
        "id": "cYnO18EejiYp"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "REN()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K9SjwWRnPtf",
        "outputId": "c9aacdac-b080-4134-a879-b6cf708c429f"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Dec 13 01:09:10.833 [\u001b[1m\u001b[34mINFO\u001b[0m] Route found: 0:46 via …Kc4P2H => 46:80 via …HFgkL5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gramatical_corretion():\n",
        "  template = \"\"\"TEXTO: {text}\n",
        "  Dado o texto acima você irá realizar correção gramatical,\n",
        "  retornando o texto corrigido, ou a frase \"Nenhum erro encontrado!\" caso\n",
        "  contrário\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
        "  llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "  text = get_corpus()\n",
        "\n",
        "  llm_chain.run(text)"
      ],
      "metadata": {
        "id": "gkxtNWacup5W"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gramatical_corretion()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O71yuvuVu67K",
        "outputId": "059855ef-5d69-411b-c43b-f648be1bfb17"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Dec 13 01:13:05.266 [\u001b[1m\u001b[34mINFO\u001b[0m] Route found: 0:46 via …Kc4P2H => 46:80 via …HFgkL5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenization():\n",
        "  template = \"\"\"TEXTO: {text}\n",
        "  Dado o texto acima você irá realizar a Tokenização do texto,\n",
        "  retornando os Tokens encontrados no formato de uma Lista do Python\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
        "  llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "  text = get_corpus()\n",
        "\n",
        "  llm_chain.run(text)"
      ],
      "metadata": {
        "id": "MWRKborGvCWX"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenization()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgR9_cPRvQRr",
        "outputId": "d14e6a6e-e9dd-4a3e-b71c-760af5bf9556"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Dec 13 01:14:17.421 [\u001b[1m\u001b[34mINFO\u001b[0m] Route found: 0:46 via …Kc4P2H => 46:80 via …HFgkL5\n"
          ]
        }
      ]
    }
  ]
}