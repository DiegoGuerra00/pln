{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "D7hJlilKM485",
        "6yExhaebs-nD",
        "eD_AJQhrwJQ6",
        "gWsBYQNtxmum"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiegoGuerra00/pln/blob/main/2023_Q3_PLN_ATIVIDADE_PR%C3%81TICA_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2023.Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **ATIVIDADE PRÁTICA 02 [Extração e Pré-processamento de Dados + Expressões Regulares]**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk0nHKabBT-"
      },
      "source": [
        "A **ATIVIDADE PRÁTICA 02** deve ser feita utilizando o **Google Colab** com uma conta\n",
        "sua vinculada ao Gmail. O link do seu notebook, armazenado no Google Drive, além do link de um repositório no GitHub e os principais resultados da atividade, devem ser enviados usando o seguinte formulário:\n",
        "\n",
        "> https://forms.gle/83JggUJ1mhgWviEaA\n",
        "\n",
        "\n",
        "**IMPORTANTE**: A submissão deve ser feita até o dia 16/10 (segunda-feira) APENAS POR UM INTEGRANTE DA EQUIPE, até às 23h59. Por favor, lembre-se de dar permissão de ACESSO IRRESTRITO para o professor da disciplina de PLN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01:**\n",
        "\n",
        "Diego Guerra / RA: 11201810534\n",
        "\n",
        "**Integrante 02:**\n",
        "\n",
        "Isolda Costa / RA: 21053014\n",
        "\n",
        "**Integrante 03:**\n",
        "\n",
        "Luis Gustavo Campos / RA: 11201811265"
      ],
      "metadata": {
        "id": "tnIArN0QY-Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LIVRO**\n",
        "---"
      ],
      "metadata": {
        "id": "6yExhaebs-nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português.`\n",
        "\n",
        ">\n",
        "\n",
        "Disponível gratuitamente em:\n",
        "  \n",
        "  > https://brasileiraspln.com/livro-pln/1a-edicao/.\n",
        "\n",
        "\n",
        "**POR FAVOR, PREENCHER OS CAPITULOS SELECIONADOS PARA A SUA EQUIPE:**\n",
        "\n",
        "`Primeiro capítulo: 3`\n",
        "\n",
        "`Segundo capítulo: 23`\n",
        "\n"
      ],
      "metadata": {
        "id": "DjJM_qhEZRy6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRIÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementar um `notebook` no `Google Colab` para identificar ERROS em 2 (DOIS) capítulos do livro **Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português**.\n",
        "\n",
        "Os capítulos devem ser selecionados na seguinte planilha:\n",
        "\n",
        "https://docs.google.com/spreadsheets/d/1ZutzQ3v1OJgsgzCvCwxXlRIQ3ChXNlHNvB63JQvYsbo/edit?usp=sharing\n",
        "\n",
        ">\n",
        "\n",
        "**IMPORTANTE:** É obrigatório usar o e-mail da UFABC.\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "**DICA:** Por favor, insira o seu nome ou da sua equipe na ordem definida na planilha. Por exemplo, se a linha correspondente ao o GRUPO 5 já foi preenchida, a próxima equipe (GRUPO 6) deverá ser informada na próxima linha da planilha.\n",
        "\n"
      ],
      "metadata": {
        "id": "fXTwkiiGs2BV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TIPOS DE ERROS**\n",
        "---\n"
      ],
      "metadata": {
        "id": "eD_AJQhrwJQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE**: consulta feita no ChatGPT\n",
        ">\n",
        "\n",
        "Um `programa Python` que utilize `expressões regulares` pode ajudar a identificar vários **tipos de erros** comuns em **livros**, especialmente erros de formatação e problemas relacionados à consistência do texto. Aqui estão alguns exemplos de erros comuns que podem ser identificados usando expressões regulares:\n",
        "\n",
        "* Erros de gramática e ortografia: erros de digitação, concordância verbal e nominal, uso incorreto de pontuação e outros erros gramaticais.\n",
        "\n",
        "* Problemas de formatação: você pode usar expressões regulares para encontrar erros de formatação, como espaços em excesso, tabulações inadequadas ou alinhamentos inconsistentes.\n",
        "\n",
        "* Abreviações e acrônimos: você pode usar expressões regulares para encontrar abreviações ou acrônimos que não foram definidos ou explicados anteriormente no texto.\n",
        "\n",
        "* Citações e referências: expressões regulares podem ser úteis para localizar citações ou referências que precisam de formatação especial.\n",
        "\n",
        "* OUTROS TIPOS DE ERROS: não considerem apenas os tipos de erros citados acima.\n",
        "\n",
        "\n",
        "**IMPORTANTE:** Lembre-se de que expressões regulares podem ser poderosas, mas também complexas. Dependendo da complexidade dos erros que você deseja identificar, pode ser necessário ajustar as expressões regulares de acordo com as características específicas do seu texto. Além disso, é importante ter em mente que as expressões regulares podem não ser a melhor ferramenta para todos os tipos de erros em livros, especialmente problemas mais contextuais ou semânticos, que podem exigir abordagens de PLN mais avançadas.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gz0DTI0KYmn6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CRITÉRIOS DE AVALIAÇÃO**\n",
        "---\n"
      ],
      "metadata": {
        "id": "gWsBYQNtxmum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A equipe que **realizar mais testes** e/ou **identificar mais erros** terá o peso diminuido na AVALIAÇÃO (Prova Escrita) em **25%** (caindo de 40 para 30). Os testes e possíveis erros devem ser contabizados de maneira separada.\n",
        "\n",
        ">\n",
        "\n",
        "Além disso, **por se tratar de um livro**, há um teste importante que deve ser feito. Lembre-se que o teste deve ser feito utilizando expressões regulares. A equipe que realizar esse teste, mesmo que o erro não ocorra nos capítulos selecionados, terá o peso diminuido na AVALIAÇÃO (Prova Escrita) em **25%** (caindo de 40 para 30).\n",
        "\n",
        "> A equipe pode considerar outros capítulos do livro para tentar identificar esse tipo de erro.\n",
        "\n",
        "**Se for a mesma equipe, o peso da avaliação será reduzido em 50% (caindo de 40 para 20)**.\n",
        "\n",
        ">\n",
        "\n",
        "**IMPORTANTE**: a diminuição no peso da AVALIAÇÃO será aplicado para todos os membros da equipe. Esse critério será aplicado apenas para uma equipe, considerando como critério de desempate a equipe que entregar primeiro a atividade no formulário.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5iHdx4BXYruQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPLEMENTAÇÃO**\n",
        "---"
      ],
      "metadata": {
        "id": "nw09lujGvfjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re"
      ],
      "metadata": {
        "id": "FavoUN5k3Sdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_errors(response):\n",
        "    errors = 0\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    paragraphs = soup.find_all('p')\n",
        "\n",
        "    for p in paragraphs:\n",
        "        text = p.get_text()\n",
        "        paragraph_errors = 0\n",
        "        error_sentences = []\n",
        "\n",
        "        # Espaçamentos incorretos\n",
        "        if len(re.findall(r'\\s{2,}', text)) > 0:\n",
        "            paragraph_errors += len(re.findall(r'\\s{2,}', text))\n",
        "            error_sentences.append(\"Espaçamentos incorretos: \" + text)\n",
        "\n",
        "        # Erros de tabulação\n",
        "        if len(re.findall(r'\\t{2,}', text)) > 0:\n",
        "            paragraph_errors += len(re.findall(r'\\t{2,}', text))\n",
        "            error_sentences.append(\"Erros de tabulação: \" + text)\n",
        "\n",
        "        # Espaços antes de pontuação\n",
        "        if len(re.findall(r'\\s+([.,;!?])', text)) > 0:\n",
        "            paragraph_errors += len(re.findall(r'\\s+([.,;!?])', text))\n",
        "            error_sentences.append(\"Espaços antes de pontuação: \" + text)\n",
        "\n",
        "        # Espaços adicionais após pontuação\n",
        "        if len(re.findall(r'([.,;!?])\\s{2,}', text)) > 0:\n",
        "            paragraph_errors += len(re.findall(r'([.,;!?])\\s{2,}', text))\n",
        "            error_sentences.append(\"Espaços adicionais após pontuação: \" + text)\n",
        "\n",
        "        # Palavras repetidas\n",
        "        if len(re.findall(r'\\b(\\w+)\\s+\\1\\b', text)) > 0:\n",
        "            paragraph_errors += len(re.findall(r'\\b(\\w+)\\s+\\1\\b', text))\n",
        "            error_sentences.append(\"Palavras repetidas: \" + text)\n",
        "\n",
        "        # Palavras iniciadas com letra minuscula apos ponto final\n",
        "        if len(re.findall(r'\\.\\s([a-z]\\w*)', text)) > 0:\n",
        "            paragraph_errors += len(re.findall(r'\\.\\s([a-z]\\w*)', text))\n",
        "            error_sentences.append(\"Palavras iniciadas com letra minuscula apos ponto final: \" + text)\n",
        "\n",
        "        # Letras maiusculas no meio de palavras\n",
        "        if len(re.findall(r'\\b\\w*[a-z]+\\w*[A-Z]+\\w*\\b', text)) > 0:\n",
        "            paragraph_errors += len(re.findall(r'\\b\\w*[a-z]+\\w*[A-Z]+\\w*\\b', text))\n",
        "            error_sentences.append(\"Letras maiusculas no meio de palavras: \" + text)\n",
        "\n",
        "        # Virgula antes do e\n",
        "        if len(re.findall(r', e\\b', text)) > 0:\n",
        "            paragraph_errors += len(re.findall(r', e\\b', text))\n",
        "            error_sentences.append(\"Virgula antes do e: \" + text)\n",
        "\n",
        "        # Virgula antes do ou\n",
        "        if len(re.findall(r', ou\\b', text)) > 0:\n",
        "            paragraph_errors += len(re.findall(r', ou\\b', text))\n",
        "            error_sentences.append(\"Virgula antes do ou: \" + text)\n",
        "\n",
        "        if paragraph_errors > 0:\n",
        "            print(f\"Foram encontrados {paragraph_errors} erros no seguinte parágrafo:\")\n",
        "            for sentence in error_sentences:\n",
        "                print(sentence)\n",
        "\n",
        "        errors += paragraph_errors\n",
        "\n",
        "    print('\\n\\nForam encontrados {} erros neste capítulo!'.format(errors))\n"
      ],
      "metadata": {
        "id": "RyUailD5vi9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_cap_3 = \"https://brasileiraspln.com/livro-pln/1a-edicao/parte2/cap3/cap3.html\"\n",
        "url_cap_23 = \"https://brasileiraspln.com/livro-pln/1a-edicao/parte9/cap23/cap23.html\"\n",
        "\n",
        "response_cap_3 = requests.get(url_cap_3)\n",
        "response_cap_23 = requests.get(url_cap_23)"
      ],
      "metadata": {
        "id": "1j_yRXB13MDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_errors(response_cap_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8FCXh8iowXn",
        "outputId": "7e397e02-2594-455d-af3d-ea812aee8d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Foram encontrados 2 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Para o treinamento de modelos de reconhecimento de fala, havia aproximadamente 60 horas, divididas em quatro pequenos conjuntos de dados de fala lida (em inglês, read speech), isto é, uma fala preparada para ser lida, em contraste com a fala espontânea: (1) o Common Voice Corpus versão 5.1 (da Mozilla)1 (2) o dataset Sid, (3) o VoxForge e (4) o LapsBM 1.42. Para o treinamento de modelos de síntese de fala, havia um conjunto de dados de um único locutor com 10 horas e 28 minutos de fala, chamado TTS-Portuguese Corpus3.\n",
            "Foram encontrados 5 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: A fala espontânea possui fenômenos que tornam o seu reconhecimento mais complexo do que o da fala lida, como as pausas preenchidas e as disfluências de edição. Exemplos de projetos que tratam da fala lida são o Librivox4, que distribui os livros de domínio público em formato de áudio. Estes áudios têm sido usados em vários projetos para criação de recursos para processamento de fala em inglês como o LibriSpeech ASR Corpus5 e o LibriTTS6, ambos alocados no repositório Open Speech and Language Resources. O LibriSpeech é um grande corpus de fala lida em inglês, com 1.000 horas, destinado a pesquisas de reconhecimento automático de fala. O LibriTTS é um corpus multilocutor derivado do LibriSpeech para pesquisas em síntese de fala, com 585 horas.\n",
            "Foram encontrados 2 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Nesse cenário de escassez de dados públicos de fala em PB para treinamento de sistemas de processamento de fala, foi concebido, em agosto de 2020, o projeto TaRSila7 do Center for Artificial Intelligence8 da Universidade de São Paulo, financiado pela IBM e FAPESP. O projeto TaRSila visa a aumentar os conjuntos de dados de fala em PB tanto para treinamento de sistemas como também para pesquisas linguísticas nas seguintes tarefas do processamento de fala:\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Além das sete tarefas acima em estudo no TaRSila, o livro sobre Processamento de Fala9 (Bäckström et al., 2022) apresenta outras tarefas típicas, como o reconhecimento e verificação de locutor, a restauração de fala e a diarização:\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Neste capítulo, apresentamos os recursos de fala criados nos três primeiros anos do projeto TaRSila para ilustrar várias das tarefas da área de processamento de fala, acima elencadas, que são definidas e exemplificadas em cada seção. Nesse percurso, fazemos um contraste com a língua inglesa que possui mais recursos para cada tarefa, citando os recursos disponibilizados na literatura tanto para o inglês como para o português.\n",
            "Foram encontrados 2 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Os vários recursos desenvolvidos no TaRSila têm o prefixo CORAA (CORpus de Áudios Anotados), que é um grande corpus multipropósito do português brasileiro no qual os arquivos de áudios estão alinhados com transcrições que foram (ou estão sendo) manualmente validadas para cada tarefa estudada no TaRSila.\n",
            "Foram encontrados 2 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: O alinhamento de um trecho de áudio com a transcrição correspondente indica o tempo de início e o tempo final do trecho (também chamado de minutagem do áudio) (veja a Figura 3.1), formando pares usados no aprendizado supervisionado de um modelo de reconhecimento de fala. O reconhecedor Whisper10 da OpenAI, por exemplo, foi treinado dessa forma. O uso de pares áudio-transcrição para treinamento de reconhecedores de fala não é a única abordagem para a tarefa, que também pode ser feita por aprendizado não supervisionado, como é o caso, por exemplo, do wav2vec-U11. Essa é uma abordagem na qual o aprendizado dispensa a necessidade de transcrições, e ocorre apenas por meio de áudio. Em todo caso, para a avaliação do desempenho de um reconhecedor, é importante que haja os pares áudio-transcrição.\n",
            "Virgula antes do e: O alinhamento de um trecho de áudio com a transcrição correspondente indica o tempo de início e o tempo final do trecho (também chamado de minutagem do áudio) (veja a Figura 3.1), formando pares usados no aprendizado supervisionado de um modelo de reconhecimento de fala. O reconhecedor Whisper10 da OpenAI, por exemplo, foi treinado dessa forma. O uso de pares áudio-transcrição para treinamento de reconhecedores de fala não é a única abordagem para a tarefa, que também pode ser feita por aprendizado não supervisionado, como é o caso, por exemplo, do wav2vec-U11. Essa é uma abordagem na qual o aprendizado dispensa a necessidade de transcrições, e ocorre apenas por meio de áudio. Em todo caso, para a avaliação do desempenho de um reconhecedor, é importante que haja os pares áudio-transcrição.\n",
            "Foram encontrados 8 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Começamos apresentando, na Seção 3.2, o TTS-Portuguese Corpus, corpus para treinamento de modelos de síntese de fala, criado e disponibilizado no início de 2020 com a fala de um único locutor. Esse corpus permitiu avançar pesquisas sobre síntese de fala, conversão de voz e uma abordagem de aumento de dados para treinar modelos de reconhecedores de fala em cenários de baixos recursos de dados. Na Seção 3.3, apresentamos o corpus CORAA NURC-SP, que contém 334 horas de fala espontânea e fala preparada de falantes de São Paulo, capital, divididas em uma parte com áudios e transcrições manuais não alinhadas originalmente (47 inquéritos) e outra parte de áudios somente (328 inquéritos). Na Seção 3.4, apresentamos o corpus CORAA ASR versão 1.1, composto por quatro corpora disponíveis na literatura, que foram validados para a tarefa de ASR, e uma coleção de TeD Talks, totalizando aproximadamente 290 horas. Na Seção 3.5, apresentamos o CORAA SER versão 1.0, composto por aproximadamente 50 minutos de segmentos de áudio rotulados em três classes: neutro, não neutro feminino e não neutro masculino, sendo que a classe neutra representa segmentos de áudio sem estado emocional bem definido e as classes não neutras representam segmentos associados a um dos estados emocionais primários da fala do locutor. Finalmente, na Seção 3.6, apresentamos o corpus do Museu da Pessoa (MuPe), com 300 horas de áudios de histórias de vida e transcrições com pontuação, que foi cedido ao TaRSila em um convênio entre o Instituto de Ciências Matemáticas e de Computação da Universidade de São Paulo (ICMC-USP), Universidade Federal de Goiás (UFG) e Museu da Pessoa. O futuro corpus, após ser anotado e anonimizado para as várias tarefas em estudo, será denominado CORAA MuPe. Na Seção 3.6 apresentamos o dataset de teste do CORAA MuPe, com aproximadamente 17 horas, e que foi usado para a avaliação da tarefa de predição de pontuação do ASR Whisper da OpenAI12. Finalizamos o capítulo com a apresentação dos recursos futuros que serão criados ou expandidos a partir dos já descritos neste capítulo (Seção 3.7).\n",
            "Virgula antes do e: Começamos apresentando, na Seção 3.2, o TTS-Portuguese Corpus, corpus para treinamento de modelos de síntese de fala, criado e disponibilizado no início de 2020 com a fala de um único locutor. Esse corpus permitiu avançar pesquisas sobre síntese de fala, conversão de voz e uma abordagem de aumento de dados para treinar modelos de reconhecedores de fala em cenários de baixos recursos de dados. Na Seção 3.3, apresentamos o corpus CORAA NURC-SP, que contém 334 horas de fala espontânea e fala preparada de falantes de São Paulo, capital, divididas em uma parte com áudios e transcrições manuais não alinhadas originalmente (47 inquéritos) e outra parte de áudios somente (328 inquéritos). Na Seção 3.4, apresentamos o corpus CORAA ASR versão 1.1, composto por quatro corpora disponíveis na literatura, que foram validados para a tarefa de ASR, e uma coleção de TeD Talks, totalizando aproximadamente 290 horas. Na Seção 3.5, apresentamos o CORAA SER versão 1.0, composto por aproximadamente 50 minutos de segmentos de áudio rotulados em três classes: neutro, não neutro feminino e não neutro masculino, sendo que a classe neutra representa segmentos de áudio sem estado emocional bem definido e as classes não neutras representam segmentos associados a um dos estados emocionais primários da fala do locutor. Finalmente, na Seção 3.6, apresentamos o corpus do Museu da Pessoa (MuPe), com 300 horas de áudios de histórias de vida e transcrições com pontuação, que foi cedido ao TaRSila em um convênio entre o Instituto de Ciências Matemáticas e de Computação da Universidade de São Paulo (ICMC-USP), Universidade Federal de Goiás (UFG) e Museu da Pessoa. O futuro corpus, após ser anotado e anonimizado para as várias tarefas em estudo, será denominado CORAA MuPe. Na Seção 3.6 apresentamos o dataset de teste do CORAA MuPe, com aproximadamente 17 horas, e que foi usado para a avaliação da tarefa de predição de pontuação do ASR Whisper da OpenAI12. Finalizamos o capítulo com a apresentação dos recursos futuros que serão criados ou expandidos a partir dos já descritos neste capítulo (Seção 3.7).\n",
            "Foram encontrados 2 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Para o inglês existem vários corpora que podem ser utilizados para treinar modelos de síntese de fala baseados em deep learning, por exemplo, os corpora VCTK (Veaux et al., 2017), LJ Speech (Ito, 2017), LibriTTS (Zen et al., 2019) e LibriTTS-R (Koizumi et al., 2023a).\n",
            "Foram encontrados 10 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: O corpus VCTK (Veaux et al., 2017) é composto por 44 horas de fala de 108 locutores, sendo 61 do sexo feminino e 47 do sexo masculino. Além disso, o corpus inclui amostras de 11 variedades linguísticas do inglês, sendo elas: britânico, americano, canadense, neozelandês, sul-africano, australiano, escocês, norte-irlandês, irlandês, indiano e galês. A taxa de amostragem dos áudios presentes nesse corpus é de 48 kHz. O corpus LJ Speech (Ito, 2017) foi derivado de audiolivros e tem aproximadamente 24 horas de fala de uma locutora profissional em uma taxa amostragem de 24 kHz. LJ Speech é um dos corpora abertos mais populares para síntese de fala de um único locutor. O corpus LibriTTS (Zen et al., 2019) também foi derivado de audiolivros e possui 585 horas de fala de 2456 locutores, sendo 1185 do sexo feminino e 1271 do sexo masculino. A taxa de amostragem dos áudios presentes nesse corpus é de 24 kHz. Por outro lado, o corpus LibriTTS-R (Koizumi et al., 2023a) foi criado com a aplicação do modelo de restauração de fala (em inglês, speech restoration) Miipher (Koizumi et al., 2023b) no dataset LibriTTS. As amostras do LibriTTS-R são idênticas às do LibriTTS, com apenas a qualidade de som melhorada. Os resultados dos experimentos mostraram que os modelos de síntese de fala treinados com o LibriTTS-R apresentaram qualidade significativamente melhor em comparação com os modelos treinados no LibriTTS.\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: A gravação do TTS-Portuguese Corpus foi realizada por um locutor masculino, nativo do português brasileiro, não profissional, em ambiente silencioso, mas sem isolamento acústico devido às dificuldades de acesso a estúdio de gravação. Todos os áudios foram gravados com frequência de amostragem de 48 kHz e resolução de 32 bits. No corpus, cada arquivo de áudio possui sua respectiva transcrição textual (a transcrição fonética não foi fornecida). O TTS-Portuguese Corpus consiste em um total de 71358 palavras faladas, 13311 palavras únicas, resultando em 3632 arquivos de áudio e totalizando 10 horas e 28 minutos de fala. Os arquivos de áudio variam em duração de 0.67 a 50.08 segundos (Casanova et al., 2022).\n",
            "Foram encontrados 3 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Em paralelo com o TTS-Portuguese Corpus, foram lançados dois conjuntos de dados para reconhecimento automático de fala do português, com boa qualidade. O primeiro, o CETUC (Alencar; Alcaim, 2008), disponibilizado publicamente por Quintanilha; Netto; Biscainho (2020), tem aproximadamente 145 horas de fala de 100 locutores. Nesse corpus, cada locutor pronunciou mil sentenças foneticamente balanceadas extraídas de textos jornalísticos; em média, 1,45 horas gravadas por locutor. Já o segundo, o corpus Multilingual LibriSpeech (MLS) (Pratap et al., 2020), é derivado dos audiolivros LibriVox e abrange 8 idiomas, incluindo o português. Para o português, os autores disponibilizaram aproximadamente 130 horas de fala provenientes de 54 locutores, uma média de 2.40 horas de fala por locutor. Embora a qualidade de ambos os corpora seja boa, os dois foram disponibilizados com uma taxa de amostragem de 16 kHz e não possuem pontuação em seus textos, dificultando a aplicação desses corpora para síntese de fala. Além disso, a quantidade de fala de cada locutor nos dois corpora é baixa, o que torna difícil criar um conjunto de dados com um vocabulário grande o suficiente para síntese de fala de um único locutor.\n",
            "Foram encontrados 2 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Além disso, mais recentemente, o corpus CML-TTS (Oliveira et al., 2023) foi proposto. O CML-TTS é baseado no corpus Multilingual LibriSpeech (MLS) e foi adaptado para treinamento de modelos de síntese de fala. O CML-TTS é composto por audiolivros em sete idiomas: holandês, francês, alemão, italiano, português, polonês e espanhol. Os autores recriaram o corpus MLS mantendo a pontuação e os áudios com uma taxa de amostragem de 24 kHz. Amostras que não atendiam às especificações descritas anteriormente foram descartadas. Para o português, após a filtragem, os autores obtiveram aproximadamente 69 horas de fala, provenientes de 31 homens e 17 mulheres.\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Existem vários estudos na literatura de processamento de fala com foco na detecção de fronteiras prosódicas nas línguas naturais (Ananthakrishnan; Narayanan, 2008; Huang; Hasegawa-Johnson; Shih, 2008; Jeon; Liu, 2009; e.g. Wightman; Ostendorf, 1991). Para o inglês, entre os recursos frequentemente utilizados em aplicações que consideram fronteiras prosódicas, podemos citar o Santa Barbara Corpus of Spoken American English (Du Bois et al., 2000--2005) e o Boston University Radio Speech Corpus (Ostendorf; Price; Shattuck-Hufnagel, 1995). O primeiro contém \\(\\approx\\)20 horas de fala espontânea de gêneros variados, transcritas e segmentadas manualmente em unidades entoacionais final e não final (Du Bois et al., 1992). Já o segundo contém 10 horas de notícias de rádio, das quais 3,5 horas estão prosodicamente anotadas de acordo com o sistema ToBI (Beckman; Hirschberg; Shattuck-Hufnagel, 2005).\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Para o português brasileiro, trabalhos desenvolvidos no âmbito do projeto C-ORAL–Brasil avançam os estudos para a detecção automática de fronteiras prosódicas na fala espontânea a partir de parâmetros fonético-acústicos e fronteiras identificadas perceptualmente por anotadores treinados (Raso; Teixeira; Barbosa, 2020; Teixeira, 2022; Teixeira; Mittman, 2018; Teixeira; Barbosa; Raso, 2018). Os estudos utilizam excertos de fala monológica masculina (8–24 minutos de áudio e 1339–3697 palavras), provenientes dos corpora anotados C-ORAL–Brasil I e II (Mello; Raso; Almeida Ferrari, no prelo; Raso; Mello, 2012a). No âmbito do projeto TaRSila, o CORAA NURC-SP, que vem sendo preparado tanto para viabilizar estudos linguísticos quanto o processamento computacional, contará com \\(\\approx\\)334 horas de fala transcrita, das quais pelo menos 40 horas serão prosodicamente anotadas.\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: O corpus do projeto NURC tem sido amplamente utilizado para estudar vários aspectos da língua falada, tendo se tornado um dos corpora mais influentes da linguística brasileira. A maioria dos estudos deriva de transcrições de pequenos subcorpora compartilhados por pesquisadores que trabalham em cada capital (Castilho, 1990, 2021), aqui referidos como corpus mínimo. Assim, a contraparte de áudio era normalmente desconsiderada devido à dificuldade de acesso às fitas magnéticas de rolo nas quais as gravações foram feitas. Recentemente, um protocolo para digitalizar, anotar, armazenar e divulgar o material do acervo do NURC-Recife, o NURC Digital (Oliveira Jr., 2016), foi desenvolvido e completamente implementado. Inspirados nesse protocolo, desenvolvemos, no âmbito do projeto TaRSila, um processo para o alinhamento texto-fala do Corpus Mínimo do NURC-SP.\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: A versão CORAA do NURC-SP é composta por 375 inquéritos (aprox. 334 horas de gravação), dos quais alguns já tinham transcrições — mas, até então, não alinhadas ao áudio — e a grande maioria é composta apenas de áudio. No âmbito do TaRSila, o NURC-SP foi dividido em três subcorpora de trabalho:\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Virgula antes do ou: Entre esses conjuntos de dados, o Corpus Mínimo é o conjunto que se encontra completamente processado (Santos et al., 2022). Ele está disponível publicamente no repositório do Portulan Clarin17 e compreende 21 arquivos de áudio e transcrições multiníveis (\\(\\approx\\)18 horas, \\(\\approx\\)155 mil palavras) alinhadas ao áudio de acordo com unidades prosódicas linguisticamente motivadas abrangendo os três gêneros textuais especificados anteriormente (DID, EF, D2). O conceito de unidade prosódica que utilizamos aqui está fundamentado nos princípios do método de segmentação prosódica do C-ORAL–BRASIL (Raso; Mello, 2012a). Portanto, no fluxo da fala, podemos reconhecer fronteiras de unidades com valores terminais ou não terminais. Quebras prosódicas terminais (TB, terminal break) marcam sequências terminadas, ou seja, comunicam a conclusão do enunciado, formando a menor unidade pragmaticamente autônoma da fala, enquanto quebras prosódicas não terminais (NTB, non-terminal break) sinalizam uma unidade prosódica não autônoma e cuja informação não está concluída dentro de um mesmo enunciado. A identificação das quebras prosódicas é baseada principalmente na relevância perceptiva (auditiva) das pistas prosódicas, mas também na inspeção visual da síntese do sinal acústico fornecida pelo Praat (Boersma; Weenink, 2023). As principais pistas para uma quebra prosódica no português brasileiro são a inserção de pausas e mudanças relacionadas à frequência fundamental e à duração (Raso; Teixeira; Barbosa, 2020; Serra, 2009).\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Virgula antes do e: O processamento do Corpus Mínimo do NURC-SP envolveu várias etapas. Em primeiro lugar, os anotadores foram treinados no uso do software Praat e na aplicação das diretrizes de anotação. Paralelamente, foram feitos o alinhamento automático entre o áudio e a transcrição original, usando o aeneas, e a preparação dos arquivos de alinhamento para anotação, que inclui uma revisão ortográfica ampla num editor de texto. Em seguida, foram realizados testes de confiabilidade entre avaliadores para avaliar a segmentação prosódica, com um valor de kappa (Capítulo 14) acima de 0.8 como critério. Na sequência, procedeu-se à anotação, que envolveu: (i) a revisão da transcrição original de acordo com as diretrizes adaptadas do projeto NURC, (ii) a correção do alinhamento automático texto-fala e (iii) a segmentação da fala em unidades prosódicas. Após a conclusão da anotação, os arquivos anotados passaram por uma inspeção realizada por um especialista, em busca de desvios significativos das diretrizes de anotação. Em seguida, a ortografia foi verificada e o texto foi normalizado, a fim de tornar o conjunto de dados adequado para o processamento de linguagem natural. Por fim, foi realizada a anotação da pontuação seguindo as normas ortográficas do português brasileiro.\n",
            "Foram encontrados 3 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: CORAA ASR19 (Candido Junior et al., 2022) é um corpus para reconhecimento automático de fala que contém também fala espontânea, um tópico pouco pesquisado em projetos similares. Esse corpus faz parte do corpus multi-tarefa CORAA e está inserido no projeto TaRSila. O CORAA ASR é a junção de cinco projetos independentes: (1) ALIP (Gonçalves, 2019); (2) C-ORAL–Brasil I (Raso; Mello, 2012a); (3) NURC-Recife (Oliveira Jr., 2016); (4) SP-2010 (Mendes; Oushiro, 2012); (5) TeDx Talks. Os quatro primeiros projetos foram originalmente criados para análises linguísticas e adaptados para a tarefa de reconhecimento automático de fala. O último é composto de áudios cedidos pela organização TED (The Eletronic Development) para a tarefa de reconhecimento e não deve ser confundido com o corpus oficial TeDx Talks Brazil, detalhado a seguir, pois existem diferenças entre os áudios disponibilizados. A fala espontânea é mais difícil de ser reconhecida do que a fala preparada, mais comum nos outros projetos, devido à presença mais frequente de fenômenos como pausas preenchidas, hesitações e revisões.\n",
            "Foram encontrados 2 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: O corpus MultiLingual LibriSpeech21 (MLS) (Pratap et al., 2020) foi pensado pelos seus autores tanto para aplicações em síntese quanto em reconhecimento de fala, devido a isso, sendo descrito aqui e na Seção 3.2. Especificamente para a tarefa de reconhecimento, pode ser combinado com outros recursos, visto que possui relativamente poucos falantes (locutores de audiolivros). Cabe aqui comentar que a aplicação de corpora para síntese em reconhecimento não é exclusividade do MLS; outros recursos como o corpus CETUC (Alencar; Alcaim, 2008) também são relevantes em ASR. Na prática, todos os recursos mencionados na Seção 3.2 podem ser efetivamente usados na tarefa de reconhecimento. Tais recursos são compostos por áudios mais limpos, geralmente em qualidade de estúdio. Por conta disso, modelos construídos unicamente sobre esse tipo de áudio são apropriados apenas para reconhecimento de fala em cenários com pouco ruído. Para contornar essa característica, o projetista pode injetar ruídos nos áudios ou combiná-los com áudios de outros projetos em diferentes níveis de qualidade.\n",
            "Foram encontrados 2 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: O MultiLingual TeDx Corpus22 (Salesky et al., 2021) foi proposto para permitir pesquisas nas áreas de reconhecimento automático da fala e tradução da fala para texto23. O recurso é composto por palestras sobre os mais variados assuntos, sendo gerenciado no escopo do projeto TEDx, vinculado ao grupo TED (Technology, Entertainment and Design). No caso da língua portuguesa, também existem traduções das transcrições para as línguas inglesa e espanhola. Além disso, áudios em espanhol e francês também contam com traduções para o português.\n",
            "Foram encontrados 3 erros no seguinte parágrafo:\n",
            "Espaços antes de pontuação: Existem outras bases para tarefa de ASR que também valem a pena ser citadas. Entre elas, o Multilingual Spoken Corpus25 (Mazumder et al., 2021) é uma base de palavras faladas em 50 idiomas e contém um recorte de cerca de 1 segundo dos áudios do Common Voice, totalizando 58 horas de áudio em português. Diferentemente das outras bases discutidas até o momento, os áudios desse corpus são compostos de palavras soltas, em vez de enunciados completos. Esse tipo de corpus se destina ao treinamento de sistemas de reconhecimento em domínios específicos (por exemplo, teleatendimento bancário). Entre as bases menores, pode-se destacar os corpora LapsBM, Sidney, VoxForge, três corpora que totalizam, aproximadamente, 4, 1 e 1 horas , respectivamente, levantados por Quintanilha; Netto; Biscainho (2020) e disponíveis para download na página do pesquisador26.\n",
            "Letras maiusculas no meio de palavras: Existem outras bases para tarefa de ASR que também valem a pena ser citadas. Entre elas, o Multilingual Spoken Corpus25 (Mazumder et al., 2021) é uma base de palavras faladas em 50 idiomas e contém um recorte de cerca de 1 segundo dos áudios do Common Voice, totalizando 58 horas de áudio em português. Diferentemente das outras bases discutidas até o momento, os áudios desse corpus são compostos de palavras soltas, em vez de enunciados completos. Esse tipo de corpus se destina ao treinamento de sistemas de reconhecimento em domínios específicos (por exemplo, teleatendimento bancário). Entre as bases menores, pode-se destacar os corpora LapsBM, Sidney, VoxForge, três corpora que totalizam, aproximadamente, 4, 1 e 1 horas , respectivamente, levantados por Quintanilha; Netto; Biscainho (2020) e disponíveis para download na página do pesquisador26.\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Por fim, algumas das bases não são voltadas a ASR, mas a tarefas relacionadas, como tradução de fala para texto. O corpus CoVoST (Wang et al., 2020; Wang; Wu; Pino, 2020) é um recorte da base Common Voice, mas com foco em tradução de fala para texto. Na versão 2, cerca de 17 horas são disponibilizadas para o português com as respectivas traduções para o inglês. O dataset Vox Populi27 (Wang et al., 2021) é uma iniciativa da empresa Meta com foco principal no treinamento semi-supervisionado e não-supervisionado de modelos de aprendizado de máquina. A base contém transcrições para algumas línguas, mas o português não é contemplado. Ao todo, 17.500 horas de áudio foram disponibilizadas para o idioma.\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Virgula antes do e: Recentemente, outras teorias e modelos têm sido propostos, obtendo-se um espectro mais detalhado de emoções. Nesse sentido, o Modelo Circumplexo de Russel (Posner; Russell; Peterson, 2005) oferece uma perspectiva complementar, ao representar as emoções em um espaço bidimensional, com eixos de valência (positivo/negativo) e intensidade (ativa/passiva), conforme apresentado de forma simplificada na Figura 3.4. Reconhecer emoções na fala tem muitas aplicações práticas, como a análise de atendimento ao cliente, apoio na avaliação do estado emocional de indivíduos durante terapias, e o desenvolvimento de assistentes virtuais mais empáticos, o que ajuda a desenvolver técnicas mais eficientes para interação humano-computador (Wani et al., 2021).\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: No âmbito do projeto TaRSila, há uma frente de trabalho denominada SER (Speech Emotion Recognition) que visa enfrentar os desafios mencionados anteriormente, com foco específico no reconhecimento de emoções na fala em português. Um diferencial importante deste projeto é o desenvolvimento de abordagens que lidam com fala espontânea, que apresenta desafios adicionais em comparação com a fala preparada. Enquanto a fala preparada envolve cenários planejados ou ensaiados, na qual o indivíduo tem tempo para estruturar suas ideias e escolher suas palavras antes de expressá-las, a fala espontânea ocorre de forma mais imediata, como conversas informais e discussões em grupo, contendo hesitações, pausas, repetições, ruídos e interrupções. Vale ressaltar que a fala espontânea pode expressar emoções de forma mais autêntica, sem ensaios ou autocontrole geralmente presentes na fala preparada.\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Entre os resultados mais recentes, incluindo os resultados obtidos no CORAA-SER, vale destacar o desempenho promissor de modelos estado da arte para reconhecimento de emoções na fala, especialmente baseados em técnicas de deep learning e transfer learning (Chen; Rudnicky, 2023; Gauy; Finger, 2022; Lope; Graña, 2023; Wagner et al., 2023). No contexto do deep learning, arquiteturas como redes neurais convolucionais (CNNs), redes neurais recorrentes (RNNs) e Transformers têm sido amplamente aplicadas, devido à sua capacidade de aprender representações intermediárias a partir dos segmentos de áudios para a tarefa de reconhecimento de emoções. Já transfer learning é uma abordagem geralmente usada em conjunto com deep learning para o reconhecimento de emoções, permitindo utilizar modelos pré-treinados em grandes corpora de áudio. Esses modelos pré-treinados são geralmente usados em tarefas de reconhecimento de fala. A ideia é explorar conhecimento prévio adquirido por esses modelos e especializá-lo para uma nova tarefa, como o reconhecimento de emoções. Essa etapa é denominada de ajuste fino e, em geral, depende de um corpus anotado, o que aumenta a importância de projetos como o CORAA-SER do TaRSila.\n",
            "Foram encontrados 3 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Para finalizar, vale destacar que a tarefa de reconhecimento de emoções a partir da fala ainda possui muitos desafios relacionados à representação computacional da fala, disponibilidade de corpora anotados e escolha de métodos de aprendizado de máquina adequados para esta tarefa. No âmbito do projeto TaRSila, a frente de trabalho SER tem buscado superar esses desafios, com ênfase na fala espontânea em português. A criação do corpus CORAA-SER foi um passo relevante nesse processo, pois já permitiu a exploração de algumas técnicas pela comunidade (Marcacini; Candido Junior; Casanova, 2022). As direções futuras e oportunidades de pesquisa neste tema são promissoras. Muitos pesquisadores estão investigando métodos de transfer learning para reconhecimento de emoções, baseado em conhecimento prévio de modelos pré-treinados para fala como o Wav2Vec (Baevski et al., 2020) e HuBERT (Hsu et al., 2021). Essas abordagens têm demonstrado um potencial promissor para melhorar a precisão e a eficiência do reconhecimento de emoções em áudio. Também devemos destacar a importância dos trabalhos que ainda exploram características prosódicas, uma vez que relacionar características de duração, intensidade, pitch e entonação com diferentes categorias de emoção fornecem maior interpretabilidade no reconhecimento de emoções a partir da fala.\n",
            "Foram encontrados 3 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: A saída de sistemas ASR convencionais é uma das principais fontes de dados que requerem capitalização e pontuação, pois é feita de uma sequência de palavras somente. Exemplos de ASR convencionais comerciais são o Google Cloud Speech-to-Text, Microsoft Azure Speech Services, IBM Watson Speech to Text, e SpeechMatics. Quando a saída é um texto escrito para ser lido em voz alta, isto é, um discurso, a tarefa é chamada de restauração da pontuação original, e para a fala conversacional/espontânea a tarefa é chamada de predição da pontuação (Păiş; Tufiş, 2022).\n",
            "Virgula antes do e: A saída de sistemas ASR convencionais é uma das principais fontes de dados que requerem capitalização e pontuação, pois é feita de uma sequência de palavras somente. Exemplos de ASR convencionais comerciais são o Google Cloud Speech-to-Text, Microsoft Azure Speech Services, IBM Watson Speech to Text, e SpeechMatics. Quando a saída é um texto escrito para ser lido em voz alta, isto é, um discurso, a tarefa é chamada de restauração da pontuação original, e para a fala conversacional/espontânea a tarefa é chamada de predição da pontuação (Păiş; Tufiş, 2022).\n",
            "Foram encontrados 2 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Apresentamos nesta seção, o dataset de teste do Corpus CORAA MuPe, balanceado por sexo, com histórias de vida de homens e mulheres, que foi criado para avaliar a tarefa de predição de pontuação no contexto de reconhecedores automáticos de fala, usando como reconhecedor o Whisper da OpenAi (Radford et al., 2022).\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: O trecho do Quadro 3.1 é de uma história de vida do MuPe29 que apresenta seis turnos de uma entrevista (P = pergunta, R = resposta) em que os sinais de pontuação foram removidos da transcrição e as primeiras palavras de cada oração são apresentadas em letras minúsculas. Esse trecho ilustra a saída de um ASR convencional que, embora não tenha erros na transcrição de palavras, ajuda a enfatizar o quanto a ausência de pontuação pode dificultar a compreensão do texto quando se torna longo.\n",
            "Foram encontrados 2 erros no seguinte parágrafo:\n",
            "Espaçamentos incorretos: Quadro 3.1  Trecho de uma história de vida do MuPe para ilustrar o formato de saída de um ASR convencional\n",
            "Letras maiusculas no meio de palavras: Quadro 3.1  Trecho de uma história de vida do MuPe para ilustrar o formato de saída de um ASR convencional\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Palavras repetidas: P – mas ela veio de onde onde ela nasceu\n",
            "Foram encontrados 3 erros no seguinte parágrafo:\n",
            "Palavras repetidas: A saída do Quadro 3.2 foi gerada pelo ASR Whisper para o mesmo trecho de áudio relacionado a mesma história de vida do MuPe mostrada no Quadro 3.1. As entidades nomeadas aparecem em negrito, para facilitar a análise. Whisper não é um ASR convencional. Ele foi foi treinado pela empresa de pesquisa em Inteligência Artificial OpenAI usando um grande conjunto de dados multilíngues coletados da web. Ele tem uma nova arquitetura multitarefas, isto é, ele é treinado para prever diversas tarefas de processamento de fala ao mesmo tempo: (i) detecção de atividade de voz, que instrui o modelo a funcionar apenas quando há uma linguagem humana específica e ser robusto ao lidar com ruído/música de fundo; (ii) tradução da fala para o inglês e (iii) reconhecimento de fala multilíngue com pontuação. Das várias pontuações inseridas na transcrição, Whisper não é capaz de gerar ponto e vírgula e dois pontos.\n",
            "Letras maiusculas no meio de palavras: A saída do Quadro 3.2 foi gerada pelo ASR Whisper para o mesmo trecho de áudio relacionado a mesma história de vida do MuPe mostrada no Quadro 3.1. As entidades nomeadas aparecem em negrito, para facilitar a análise. Whisper não é um ASR convencional. Ele foi foi treinado pela empresa de pesquisa em Inteligência Artificial OpenAI usando um grande conjunto de dados multilíngues coletados da web. Ele tem uma nova arquitetura multitarefas, isto é, ele é treinado para prever diversas tarefas de processamento de fala ao mesmo tempo: (i) detecção de atividade de voz, que instrui o modelo a funcionar apenas quando há uma linguagem humana específica e ser robusto ao lidar com ruído/música de fundo; (ii) tradução da fala para o inglês e (iii) reconhecimento de fala multilíngue com pontuação. Das várias pontuações inseridas na transcrição, Whisper não é capaz de gerar ponto e vírgula e dois pontos.\n",
            "Foram encontrados 2 erros no seguinte parágrafo:\n",
            "Espaçamentos incorretos: Quadro 3.2  História de vida do MuPe gerada pelo ASR Whisper\n",
            "Letras maiusculas no meio de palavras: Quadro 3.2  História de vida do MuPe gerada pelo ASR Whisper\n",
            "Foram encontrados 2 erros no seguinte parágrafo:\n",
            "Espaçamentos incorretos: Quadro 3.3  História de vida do MuPe gerada por transcrição manual\n",
            "Letras maiusculas no meio de palavras: Quadro 3.3  História de vida do MuPe gerada por transcrição manual\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Virgula antes do e: P – Tá, e sua mãe, ela fazia o que?\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Virgula antes do e: R – Ela veio para São Paulo no final dos anos 40, porque a situação em Pernambuco estava no campo, estava muito difícil, havia seca, então, ela e três, duas irmãs e um irmão vieram pra São Paulo, início para trabalhar na casa de uma tia dela, no bairro da Penha, que tinha uma pensão, aí, depois cada um foi como a maioria dos Nordestinos, chega, fica na casa dos familiares e depois vai arrumando emprego, aí vai arrumando sua vida,ou seja, minha mãe e meu pai também vieram pra São Paulo, porque lá em Minas não havia trabalho, e ele como tinha essa vontade de trabalhar acredito eu, ele antes de completar 18 anos, ele fugiu de casa, veio para São Paulo e ele era o caçula do primeiro casamento da minha vó.\n",
            "Foram encontrados 3 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: O Corpus CORAA MuPe está atualmente em fase de processamento. Ele é um conjunto de 300 horas de histórias de vida que foi cedido ao projeto TaRSila em um convênio de colaboração iniciado em dezembro de 2022 entre o MuPe, o ICMC-USP e a UFG. O objetivo inicial do convênio é o estudo e desenvolvimento de modelos de ASR, de métodos de segmentação automática de transcrição e modelagem de tópicos baseada nas transcrições de vídeos.\n",
            "Foram encontrados 2 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: O MuPe é um museu virtual que visa contar e preservar as histórias de vida das pessoas e incentiva a participação de pessoas de diferentes idades, sexos, raças e profissões. Fundado em 1991, o MuPe contém atualmente um rico e extenso acervo digital de narrativas de fala espontânea em português, chamadas de histórias de vida que são contadas pelas próprias pessoas ou por terceiros.\n",
            "Foram encontrados 2 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Depois de gravadas, as histórias de vida coletadas pelo MuPe são transcritas e revisadas. As transcrições possuem anotações de risos, palmas, assobios, fala emocionada, pausas, entre outros, utilizando parênteses. Além disso, as expansões de acrônimos são anotadas usando colchetes. A transcrição é segmentada em enunciados, com pontuação, usando sete sinais de pontuação (ver Tabela 3.5). Os turnos são indicados pelos rótulos P/1 (e P/2) e R seguidos da transcrição do turno, onde P/i (i = 1 ou 2) indica o entrevistador (1 ou 2 entrevistadores) e R o entrevistado. No entanto, como as pausas preenchidas e disfluências de edição (por exemplo, revisões e repetições) comuns na fala espontânea não são anotadas, a transcrição do MuPe pode ser chamada de transcrição textual adaptada.\n",
            "Foram encontrados 3 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: O dataset de teste é composto por 10 narrativas de vida retiradas do projeto Ponto de Cultura da plataforma MuPe. O Corpus MuPe contém 280 narrativas de vida, sendo a maioria delas com conteúdo transcrito completo; algumas poucas apresentam somente um resumo. A Tabela 3.4 mostra as estatísticas do dataset de teste, dividido em duas amostras: narrativas masculinas e femininas. O dataset de teste do MuPe é composto por 1.349 turnos e totaliza aproximadamente 17 horas. Ele está disponibilizado publicamente30, com os links dos áudios e as transcrições manuais anonimizadas, cujos nomes completos dos entrevistados (ou dos familiares) masculinos foram trocados por “João” e os femininos por “Maria”, para não haver grande perda de material original e ainda atender ao requisito do convênio para disponibilização pública. O nome da família foi trocado por “nome da família”.\n",
            "Foram encontrados 2 erros no seguinte parágrafo:\n",
            "Virgula antes do e: A abordagem dominante na literatura, conhecida como abordagem em cascata, é treinar um modelo de reconhecimento de fala (ou usar um pronto) e um modelo de predição de pontuação separadamente, e, em seguida, colocá-los em cascata, ou seja, inserir marcas de pontuação na transcrição gerada pelo ASR como uma etapa de pós-processamento. Para cada token na saída do ASR, as features acústicas do áudio são obtidas e são usadas como entrada para o módulo de predição de pontuação (Figura 3.6, esquerda).\n",
            "Virgula antes do ou: A abordagem dominante na literatura, conhecida como abordagem em cascata, é treinar um modelo de reconhecimento de fala (ou usar um pronto) e um modelo de predição de pontuação separadamente, e, em seguida, colocá-los em cascata, ou seja, inserir marcas de pontuação na transcrição gerada pelo ASR como uma etapa de pós-processamento. Para cada token na saída do ASR, as features acústicas do áudio são obtidas e são usadas como entrada para o módulo de predição de pontuação (Figura 3.6, esquerda).\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: No artigo de Gris et al. (2023), foram revisados cinco trabalhos da literatura para uma comparação com o uso do Whisper no dataset de teste do MuPe32. A Tabela 3.6 mostra um resumo dos trabalhos avaliados, com indicação do corpus usado na avaliação e seu tamanho em número de enunciados/duração em horas; os conjuntos de teste do IWSLT 2011 são apresentados em número de palavras para transcrições manuais (Referência) e transcrições automáticas (realizadas por um ASR), nesta ordem (Che et al., 2016).\n",
            "Foram encontrados 4 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Alam; Khan; Alam (2020) avaliaram vários modelos de língua para o inglês (BERT, RoBERTa, ALBERT, DistilBERT) e modelos multilíngues para o bengali (mBERT, XLM-RoBERTa) disponíveis no repositório Hugging Face33. Avaliaram o desempenho dos quatro rótulos: Vírgula, Ponto, Pergunta e O (sem sinal de pontuação seguido), nos dois conjuntos de teste do IWSLT 2011.\n",
            "Foram encontrados 2 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Yi; Tao (2019) propuseram um modelo baseado em auto-atenção usando embeddings de palavra e de fala, respectivamente Glove (Pennington; Socher; Manning, 2014) e Speech2Vec (Chung; Glass, 2018), resolvendo o problema de dependência dos dados de fala alinhados com sua transcrição, pois para muitas línguas há carência destes recursos. Como Alam; Khan; Alam (2020), os autores também avaliaram seu modelo no conjunto de dados do IWSLT 2011, mas os resultados de Alam; Khan; Alam (2020) ainda são melhores do que os de Yi; Tao (2019) (exceto para ponto de interrogação), provavelmente devido ao fato de Alam; Khan; Alam (2020) usar uma técnica de aumento de dados, que melhora o desempenho em dados com ruídos, e um modelo baseado em Transformers.\n",
            "Virgula antes do e: Yi; Tao (2019) propuseram um modelo baseado em auto-atenção usando embeddings de palavra e de fala, respectivamente Glove (Pennington; Socher; Manning, 2014) e Speech2Vec (Chung; Glass, 2018), resolvendo o problema de dependência dos dados de fala alinhados com sua transcrição, pois para muitas línguas há carência destes recursos. Como Alam; Khan; Alam (2020), os autores também avaliaram seu modelo no conjunto de dados do IWSLT 2011, mas os resultados de Alam; Khan; Alam (2020) ainda são melhores do que os de Yi; Tao (2019) (exceto para ponto de interrogação), provavelmente devido ao fato de Alam; Khan; Alam (2020) usar uma técnica de aumento de dados, que melhora o desempenho em dados com ruídos, e um modelo baseado em Transformers.\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Sunkara et al. (2020) propõem uma nova estrutura de fusão multimodal de embeddings lexicais e acústicos para previsão de pontuação em fala espontânea chamada arquitetura de aprendizagem semissupervisionada multimodal (MuSe). Embora os resultados de Sunkara et al. (2020) não sejam diretamente comparáveis com os de Zelasko et al. (2018) no Fisher Corpus, pois as divisões dos conjuntos de dados são diferentes, Sunkara et al. (2020) obtiveram melhor desempenho em todas as classes de pontuação.\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Nozaki et al. (2022) propuseram um modelo end-to-end para reconhecimento de fala com pontuação (Figura 3.6, direita). Eles usaram dois conjuntos de dados de idiomas diferentes: o MuST-C, um corpus multilíngue34 (Di Gangi et al., 2019) que foi usado como o conjunto de dados em inglês e o JCALL, um conjunto de dados fechado que consiste de gravações de áudio de conversas, foi usado como o conjunto de dados em japonês.\n",
            "Foram encontrados 2 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: A OpenAI lançou, em setembro de 2022, o Whisper ASR. Embora também seja um modelo de ASR end-to-end semelhante à abordagem de Nozaki et al. (2022), ele tem duas diferenças importantes: é de código aberto e foi treinado em um dataset grande e multilíngue. Whisper é um ASR capaz de incluir pontuação e capitalização nas transcrições (Radford et al., 2022), embora seja somente capaz de gerar 5 tipos de pontuações: reticências, ponto final, vírgulas, ponto de interrogação e ponto de exclamação. O conjunto de dados de teste do MuPe possui duas pontuações a mais (ponto e vírgula e dois pontos).\n",
            "Foram encontrados 10 erros no seguinte parágrafo:\n",
            "Espaços antes de pontuação: Apresentamos neste capítulo os recursos de processamento de fala que foram criados nos três anos iniciais do projeto TaRSila. Dois grandes corpora estão ainda em fase de processamento para serem lançados em 2024: (i) o Corpus CORAA NURC-SP e o Corpus CORAA MuPe. Além dos estudos previstos no convênio com o MuPe, uma tarefa futura será a compilação de um dataset para modelagem e teste de sistemas TTS, nos moldes do LibriTTS, citado na Seção 3.2 , já que as histórias de vida cedidas foram gravadas em estúdio. A diferença entre o LibriTTS e o corpus a ser criado a partir do Corpus MuPe está no gênero dos textos: as histórias de vida do MuPe são exemplos da fala espontânea, guiada por entrevista, e o LibriTTS contém fala lida.\n",
            "Letras maiusculas no meio de palavras: Apresentamos neste capítulo os recursos de processamento de fala que foram criados nos três anos iniciais do projeto TaRSila. Dois grandes corpora estão ainda em fase de processamento para serem lançados em 2024: (i) o Corpus CORAA NURC-SP e o Corpus CORAA MuPe. Além dos estudos previstos no convênio com o MuPe, uma tarefa futura será a compilação de um dataset para modelagem e teste de sistemas TTS, nos moldes do LibriTTS, citado na Seção 3.2 , já que as histórias de vida cedidas foram gravadas em estúdio. A diferença entre o LibriTTS e o corpus a ser criado a partir do Corpus MuPe está no gênero dos textos: as histórias de vida do MuPe são exemplos da fala espontânea, guiada por entrevista, e o LibriTTS contém fala lida.\n",
            "Virgula antes do e: Apresentamos neste capítulo os recursos de processamento de fala que foram criados nos três anos iniciais do projeto TaRSila. Dois grandes corpora estão ainda em fase de processamento para serem lançados em 2024: (i) o Corpus CORAA NURC-SP e o Corpus CORAA MuPe. Além dos estudos previstos no convênio com o MuPe, uma tarefa futura será a compilação de um dataset para modelagem e teste de sistemas TTS, nos moldes do LibriTTS, citado na Seção 3.2 , já que as histórias de vida cedidas foram gravadas em estúdio. A diferença entre o LibriTTS e o corpus a ser criado a partir do Corpus MuPe está no gênero dos textos: as histórias de vida do MuPe são exemplos da fala espontânea, guiada por entrevista, e o LibriTTS contém fala lida.\n",
            "Foram encontrados 2 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Em primeiro lugar agradecemos aos bolsistas do projeto TaRSila que foram incansáveis nas revisões das transcrições automáticas, no treinamento e teste dos modelos para vários sistemas de processamento de fala. Este trabalho faz parte de um Acordo de Transferência de Tecnologia entre Museu da Pessoa (MuPe), Instituto de Ciências Matemáticas e de Computação da Universidade de São Paulo (ICMC/USP) e Universidade Federal de Goiás. Este trabalho foi realizado no Centro de Inteligência Artificial (C4AI-USP), com apoio da Fundação de Amparo à Pesquisa do Estado de São Paulo (bolsa FAPESP nº 2019/07665-4) e da IBM Corporation. Agradecemos também o apoio do Centro de Excelência em Inteligência Artificial (CEIA) financiado pela Fundação do Estado de Goiás (bolsa FAPEG nº 201910267000527). Este projeto também foi apoiado pelo Ministério da Ciência, Tecnologia e Inovação, com recursos da Lei nº 8.248, de 23 de outubro de 1991, no âmbito do PPI-SOFTEX, coordenado pela Softex e publicado Residência no TIC 13, DOU 01245.010222/2022-44.\n",
            "Foram encontrados 2 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: O dataset Sid, o VoxForge e o LapsBM 1.4 estão disponíveis em: https://igormq.github.io/datasets/↩︎\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Virgula antes do e: Convém observar que alguns valores são estimativas dos respectivos autores. Muitos projetos estão em atividade, e os valores apresentados devem aumentar com passar do tempo.↩︎\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: MuST-C inclui gravações de áudio de TED Talks em inglês alinhadas no nível da frase com suas transcrições e traduções manuais.↩︎\n",
            "\n",
            "\n",
            "Foram encontrados 121 erros neste capítulo!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_errors(response_cap_23)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVO0LJjfoyon",
        "outputId": "6b5c8f9a-3022-4cf6-a339-4258b320abff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Palavras iniciadas com letra minuscula apos ponto final: Larissa A. de Freitas \n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Virgula antes do e: Os sistemas de PLN são ferramentas indispensáveis para compreender, analisar e extrair informações. O estudo dos estilos de linguagem utilizados nas redes sociais ajuda a melhorar a compreensão de textos informais. As redes sociais são fontes valiosas de informação e seus conteúdos podem ser utilizados como corpora para treinar e testar algoritmos de PLN, permitindo que pesquisadores e desenvolvedores trabalhem com exemplos reais e relevantes. Visto que o Brasil é um dos países com maior presença nas redes sociais, e o português é o idioma predominante nessas interações, tem-se aqui uma área muito fértil para o desenvolvimento de estudos de aplicações de abordagens e PLN.\n",
            "Foram encontrados 3 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: O Whatsapp7 permite que os usuários troquem mensagens privadas. Apesar de ser usado principalmente para conversas individuais, o WhatsApp possui recursos de grupos de conversação, onde podem participar até 256 usuários, e encaminhamento de mensagens (Cabral et al., 2021). Concebido como um aplicativo de mensagens instantâneas, o WhatsApp evoluiu para uma plataforma multifacetada, permitindo não apenas conversas privadas, mas também a formação de grupos e comunidades, compartilhamento de mídia, chamadas de voz e vídeo e até mesmo recursos empresariais.\n",
            "Virgula antes do e: O Whatsapp7 permite que os usuários troquem mensagens privadas. Apesar de ser usado principalmente para conversas individuais, o WhatsApp possui recursos de grupos de conversação, onde podem participar até 256 usuários, e encaminhamento de mensagens (Cabral et al., 2021). Concebido como um aplicativo de mensagens instantâneas, o WhatsApp evoluiu para uma plataforma multifacetada, permitindo não apenas conversas privadas, mas também a formação de grupos e comunidades, compartilhamento de mídia, chamadas de voz e vídeo e até mesmo recursos empresariais.\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Virgula antes do e: A partir de definições encontradas na literatura, termos diferentes, porém semelhantes, podem ser enquadrados como discursos simbolicamente prejudiciais (por exemplo, discurso perigoso, discurso tóxico, discurso de ódio, discurso intolerante e outros). Certos discursos possuem o potencial de causar danos significativos, inclusive críticos, e podem ser considerados tóxicos (Tirrell, 2018). Discursos tóxicos podem assumir diversas formas, podendo ser um discurso persistente ou momentâneo, afetar indivíduos ou a sociedade como um todo, causando danos temporários ou permanentes. O impacto de toxinas discursivas é de natureza social, afetando comunidades e prejudicando indivíduos pertencentes aos grupos alvo. Essas toxinas podem incluir palavras ofensivas, insultos, discriminação, discurso de ódio, difamação, ameaças ou qualquer forma de linguagem que busque macular, menosprezar ou ferir a dignidade e a integridade de indivíduos pertencentes ao grupo alvo. De acordo com Kumar et al. (2023), comentários tóxicos são a principal forma de ódio e assédio online.\n",
            "Foram encontrados 3 erros no seguinte parágrafo:\n",
            "Virgula antes do e: Os grupos alvo de discursos tóxicos podem variar dependendo do contexto e da natureza do discurso. Grupos frequentemente alvos de discursos tóxicos incluem minorias étnicas e raciais, comunidade LGBTQIA, mulheres, religiões minoritárias, portadores de deficiência, refugiados e imigrantes, e grupos políticos ou ideológicos. Contudo, qualquer grupo ou indivíduo pode ser alvo de discursos tóxicos, e a disseminação desse tipo de linguagem é prejudicial para a sociedade como um todo. Indivíduos pertencentes a diferentes grupos discriminados, podem ainda ser alvos de discursos interseccionais que os atacam por múltiplas frentes. A Figura 23.1, adaptada de Santana (2023), ilustra um caso em que ataques interseccionais dirigidos a uma entidade foram disseminados na Internet. A imagem busca ilustrar o que aconteceu após o assassinato em 2018 da socióloga e política brasileira Marielle Franco, onde uma rede de ódio e desinformação gerou diversos comentários online atacando sua imagem por diversas características que ela possuía, e até outros traços que foram inadvertidamente atribuídos a ela. Teixeira; Zamora (2019) destacam que Marielle - mulher negra, assumidamente bissexual, favelada, defensora política dos direitos humanos - foi, sem dúvida, atravessada por todo tipo de opressão desencadeada pelo sistema machista, racista e classista. Os ataques registrados neste caso foram motivados pelo ódio.\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Apesar dos diversos avanços pelos quais a área de PLN vem passando, a detecção de discursos tóxicos ainda é um desafio latente. O desenvolvimento de algoritmos de PLN e Aprendizado de Máquina (AM) para detectar esses tipos de conteúdo depende da disponibilidade de corpora anotados para treinamento. Conforme identificado por Trajano; Bordini; Vieira (2023) quase todos os sistemas de detecção de toxicidade usam modelos de aprendizado supervisionado que requerem uma grande quantidade de dados rotulados9. Entre estes corpora, podemos ressaltar recursos para a língua a portuguesa como o ToLD-Br desenvolvido por Leite et al. (2020).\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: O ToLD-Br (Leite et al., 2020) é um conjunto de dados capturado do Twitter/X entre julho e agosto de 2019 com a ferramenta GATE Cloud’s Twitter Collector10. Elaborado para estudos sobre classificação automática de comentários tóxicos, este conjunto de dados tem como objetivo equilibrar o viés de anotação. Para tanto, 42 anotadores foram selecionados, com base em suas informações demográficas. Este corpus apresenta um conjunto de 21000 tweets em português manualmente anotados por três diferentes anotadores em sete categorias: LGBTQ+fobia, obsceno, insulto, racismo, misoginia e/ou xenofobia.\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Virgula antes do ou: O estudo de discursos tóxicos é de suma importância por várias razões, abordando questões sociais, éticas e técnicas. O volume de informações gerado a partir das redes sociais e plataformas online aumenta a exposição a discursos tóxicos, o que pode causar impactos negativos na saúde mental e emocional dos usuários. Compreender e identificar esses discursos é fundamental para criar um ambiente digital mais saudável e seguro para todos. Discursos tóxicos frequentemente incluem discursos de ódio e manifestação de linguagem imprópria, ou seja, atos que podem promover a violência, intolerância e discriminação contra grupos específicos. A análise desses discursos permite identificar padrões prejudiciais e trabalhar para mitigar seus efeitos negativos.\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Virgula antes do e: Muitas iniciativas têm sido empreendidas com o intuito de possibilitar a detecção automatizada de discursos de ódio nas diferentes plataformas. Conforme mencionado por Fortuna; Nunes (2018), esse crescente interesse não se restringe apenas à ampla cobertura midiática, mas também à crescente relevância política do tema. No entanto, os autores também destacam desafios latentes, como a falta de técnicas automáticas adequadas e a escassez de dados confiáveis sobre o discurso de ódio, que continuam motivando pesquisas nessa área. Analisando estatísticas brasileiras, Dadico (2020) explana que os dados indicam que o ódio sobrevitimiza pessoas de grupos identificados por critérios de raça, cor, etnia, sexo, orientação sexual, identidade de gênero, origem nacional e regional, sem-teto ou deficiência, entre outros atributos que os expõem a maior vulnerabilidade social. Apesar da normalização do ódio, esse discurso é parte de uma narrativa socio-histórica que traz em si os modos de pensar de uma cultura. É pela língua que nos mostramos como somos, e enquanto ela pode ser um instrumento de empoderamento, também pode gerar exclusão, opressão. O avanço de estudos de aplicação de abordagens de PLN para a detecção de tais conteúdos é essencial. Entretanto, avanços nesta área de estudos dependem fundamentalmente de conjuntos de dados anotados, ferramentas de análise de texto e modelos específicos disponibilizados para tal.\n",
            "Foram encontrados 3 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Para o português, Fortuna et al. (2019) criou um conjunto de dados para a classificação do discurso de ódio, o HLPHSD11. As instâncias deste conjunto foram coletadas através do uso da API do Twitter/X. Para isso, foram usadas palavras-chave e hashtags como #dyke ou #womensPlaceIsInTheKitchen coletadas entre janeiro e março de 2017 (majoritariamente). Este conjunto de dados contém conteúdo de 1156 usuários diferentes e abrange diferentes tipos de discriminação, com base sobre religião, gênero, orientação sexual, etnia, e migração. Nele foram feitas duas anotações: binária (“é discurso de ódio” ou “não é discurso de ódio”) e hierárquica (“racismo”, “sexismo”, ou “homofobia”). Na anotação binária, cada tweet foi anotado por três diferentes anotadores. Por fim, uma votação majoritária para determinar classificação final foi realizada nos 3059 tweets. Os autores realizaram experimentos utilizando uma LSTM combinada com embeddings pré-treinados para realizar uma classificação base a partir deste conjunto de dados e assim demonstrar seu potencial de uso. O resultado obtido foi a medida-F de 78%.\n",
            "Virgula antes do e: Para o português, Fortuna et al. (2019) criou um conjunto de dados para a classificação do discurso de ódio, o HLPHSD11. As instâncias deste conjunto foram coletadas através do uso da API do Twitter/X. Para isso, foram usadas palavras-chave e hashtags como #dyke ou #womensPlaceIsInTheKitchen coletadas entre janeiro e março de 2017 (majoritariamente). Este conjunto de dados contém conteúdo de 1156 usuários diferentes e abrange diferentes tipos de discriminação, com base sobre religião, gênero, orientação sexual, etnia, e migração. Nele foram feitas duas anotações: binária (“é discurso de ódio” ou “não é discurso de ódio”) e hierárquica (“racismo”, “sexismo”, ou “homofobia”). Na anotação binária, cada tweet foi anotado por três diferentes anotadores. Por fim, uma votação majoritária para determinar classificação final foi realizada nos 3059 tweets. Os autores realizaram experimentos utilizando uma LSTM combinada com embeddings pré-treinados para realizar uma classificação base a partir deste conjunto de dados e assim demonstrar seu potencial de uso. O resultado obtido foi a medida-F de 78%.\n",
            "Virgula antes do ou: Para o português, Fortuna et al. (2019) criou um conjunto de dados para a classificação do discurso de ódio, o HLPHSD11. As instâncias deste conjunto foram coletadas através do uso da API do Twitter/X. Para isso, foram usadas palavras-chave e hashtags como #dyke ou #womensPlaceIsInTheKitchen coletadas entre janeiro e março de 2017 (majoritariamente). Este conjunto de dados contém conteúdo de 1156 usuários diferentes e abrange diferentes tipos de discriminação, com base sobre religião, gênero, orientação sexual, etnia, e migração. Nele foram feitas duas anotações: binária (“é discurso de ódio” ou “não é discurso de ódio”) e hierárquica (“racismo”, “sexismo”, ou “homofobia”). Na anotação binária, cada tweet foi anotado por três diferentes anotadores. Por fim, uma votação majoritária para determinar classificação final foi realizada nos 3059 tweets. Os autores realizaram experimentos utilizando uma LSTM combinada com embeddings pré-treinados para realizar uma classificação base a partir deste conjunto de dados e assim demonstrar seu potencial de uso. O resultado obtido foi a medida-F de 78%.\n",
            "Foram encontrados 2 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Outro conjunto de dados disponível na literatura que foi elaborado para estudos sobre a classificação do discurso de ódio é o HateBR12, elaborado por Vargas et al. (2022). O HateBR é composto por 7000 textos sobre o domínio político coletados através da API do Instagram. Neste conjunto de dados, constam postagens de seis contas pré-definidas (gênero - 4 mulheres e 2 homens, posição política - 3 liberais e 3 conservadores). Sua anotação foi feita de três maneiras: binária (“é ofensivo” ou “não é ofensivo”), granularidade (“levemente ofensivo”, “moderadamente ofensivo” e “altamente ofensivo”) e grupos de discursos de ódio (“partidarismo”, “sexismo”, “intolerância religiosa”, “apologia pela ditadura”, “gordofobia”, “homofobia”, “racismo”, “anti-semitismo” e “xenofobia”).\n",
            "Foram encontrados 2 erros no seguinte parágrafo:\n",
            "Virgula antes do e: Embora muito do que é visto em discursos tóxicos seja também discurso de ódio, cabe ressaltar que outras formas de toxicidade também são manifestas através de discursos. Há também o que chamamos de linguagem ofensiva. Diferentemente de discursos de ódio, os quais são voltados para indivíduos ou grupos específicos de pessoas com base em características identitárias, a linguagem ofensiva tem a intenção de magoar, insultar ou provocar os sentimentos das pessoas, sem necessariamente ter um objetivo discriminatório. É importante notar que a linha entre discurso de ódio e linguagem ofensiva nem sempre é clara, e o contexto em que o conteúdo é apresentado pode influenciar a percepção do quão prejudicial ele é. Isto é, todo discurso de ódio é uma linguagem ofensiva, mas nem toda linguagem que é ofensiva é também um discurso de ódio. Ambos podem ser prejudiciais e problemáticos em diferentes aspectos, e muitas vezes é necessário avaliar cuidadosamente o conteúdo para entender suas implicações e tomar medidas apropriadas para mitigar seus efeitos negativos. Tal qual os demais discursos considerados tóxicos, é importante também o desenvolvimento de meios de detecção de linguagem ofensiva.\n",
            "Foram encontrados 5 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Conjuntos de dados voltados para a detecção deste tipo de linguagem podem ser usados em um contexto que não é necessariamente de ódio. Para o português brasileiro, Trajano; Bordini; Vieira (2023) construiu um conjunto de dados voltados a detecção de linguagem ofensiva, nomeado OLID-Br13. Inspirado em outros corpora similares (do inglês, Offensive Language Identification Datasets ou OLID), construídos para outros idiomas, o OLID-Br reúne dados de diferentes fontes: Twitter/X, YouTube, e ainda de outros conjuntos de dados em português anotados com um esquema de anotação distinto do proposto. Os conjuntos de dados utilizados foram o OffComBR de Pelle; Moreira (2017), NCCVG14 de Nascimento et al. (2019), HLPHSD de Fortuna et al. (2019), e ToLD-Br de Leite et al. (2020). O conjunto de dados OLID-BR contém anotações para cinco tarefas, são elas: (1) classificação de comentário tóxico: classificação binária utilizada para identificar se um comentário é ou não tóxico; (2) detecção do tipo de toxicidade: classificação multi-rótulo que identifica os rótulos de toxicidade presentes em um comentário tóxico; (3) classificação de alvo de toxicidade: classificação binária que prevê se um comentário tóxico é direcionado ou não; (4) identificação do tipo de alvo de toxicidade: classificação multiclasse que identifica o tipo de alvo de um comentário direcionado; e (5) categorização de spans: tarefa voltada a detecção de spans (parte de um texto) em um comentário tóxico. O conjunto de dados contém 6.354 (extensível para 13.538) comentários rotulados usando um esquema de anotação de três camadas com granulação fina compatível com conjuntos de dados em outros idiomas, o que permite o treinamento de modelos multilíngues.\n",
            "Virgula antes do e: Conjuntos de dados voltados para a detecção deste tipo de linguagem podem ser usados em um contexto que não é necessariamente de ódio. Para o português brasileiro, Trajano; Bordini; Vieira (2023) construiu um conjunto de dados voltados a detecção de linguagem ofensiva, nomeado OLID-Br13. Inspirado em outros corpora similares (do inglês, Offensive Language Identification Datasets ou OLID), construídos para outros idiomas, o OLID-Br reúne dados de diferentes fontes: Twitter/X, YouTube, e ainda de outros conjuntos de dados em português anotados com um esquema de anotação distinto do proposto. Os conjuntos de dados utilizados foram o OffComBR de Pelle; Moreira (2017), NCCVG14 de Nascimento et al. (2019), HLPHSD de Fortuna et al. (2019), e ToLD-Br de Leite et al. (2020). O conjunto de dados OLID-BR contém anotações para cinco tarefas, são elas: (1) classificação de comentário tóxico: classificação binária utilizada para identificar se um comentário é ou não tóxico; (2) detecção do tipo de toxicidade: classificação multi-rótulo que identifica os rótulos de toxicidade presentes em um comentário tóxico; (3) classificação de alvo de toxicidade: classificação binária que prevê se um comentário tóxico é direcionado ou não; (4) identificação do tipo de alvo de toxicidade: classificação multiclasse que identifica o tipo de alvo de um comentário direcionado; e (5) categorização de spans: tarefa voltada a detecção de spans (parte de um texto) em um comentário tóxico. O conjunto de dados contém 6.354 (extensível para 13.538) comentários rotulados usando um esquema de anotação de três camadas com granulação fina compatível com conjuntos de dados em outros idiomas, o que permite o treinamento de modelos multilíngues.\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Com a proliferação das redes sociais e das plataformas de avaliação online (tais como: TripAdvisor15, Booking16 e Airbnb17), assim como em diversos sites de e-commerce, uma infinidade de textos opinativos são publicados diariamente. Estes textos têm grande potencial para apoiar os processos de tomada de decisão (Zhang et al., 2023). A Análise de Sentimento (AS) estuda as opiniões, sentimentos, avaliações, apreciações, atitudes e emoções em relação a entidades como produtos, serviços, organizações, indivíduos, problemas, eventos, tópicos e seus diferentes aspectos expressos em textos (Liu, 2012). Nesta área desenvolvem-se aplicações em diversos campos do conhecimento como: política, finanças e marketing.\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Virgula antes do e: No trabalho de Pereira (2021) é apresentada uma pesquisa de AS em língua portuguesa. Nele são apresentadas os principais tipos de abordagens de AS, as quais podem ser baseadas em AM (classificação também proposta por Tan; Lee; Lim (2023)), em léxico de sentimento, em conceitos, e híbrida. Abordagens baseadas em AM utilizam algoritmos de AM tradicionais. Já, abordagens baseadas em léxico de sentimento obtêm o grau de polaridade de opinião ou emoção de um léxico de sentimento. As abordagens baseadas em conceito usam redes de conceito (por exemplo: ontologias) para realizar a análise semântica do texto. Por fim, as abordagens híbridas, combinam as abordagens mencionadas anteriormente.\n",
            "Foram encontrados 9 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Dentre os recursos para o português brasileiro, podemos citar: os léxicos de sentimentos (OpLexicon18 de Souza et al. (2011), OpenWordNet-PT19 de De Paiva; Rademaker; Melo (2012), SentiLex20 de Silva; Carvalho; Sarmento (2012), Reli-Lex21 de Freitas (2013), Word NetAffect-BR22 de Pasqualotti (2015), Personalitatem Lexicon de Machado et al. (2015), AffectPT-BR23 de Carvalho; Santos; Guedes (2018), LexReli de Machado; Pardo; Ruiz (2018), Brazilian Portuguese LIWC Dictionary24 de Balage Filho; Pardo; Aluísio (2013) e os corpora anotados para a tarefa de AS (ReLi de Freitas et al. (2012), comentários sobre hotéis publicados no TripAdvisor de Freitas (2015), comentários sobre produtos publicados no Buscapé de Avanço; Nunes (2014), comentários sobre restaurantes de Farias et al. (2016), TweetSentBR de Brum; Nunes (2018), UTLCorpus de Sousa; Brum; Nunes (2019) e tweets sobre a pandemia de COVID-19 de Vargas; Santos; Rocha (2020)).\n",
            "Foram encontrados 12 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: O OpLexicon (Souza et al., 2011) possui 30.322 palavras (23.433 adjetivos e 6.889 verbos) e foi construído com base em um corpus do português brasileiro (composto por 346 resenhas de filmes e 970 textos jornalísticos), no thesaurus denominado TEP (do português, Thesaurus Eletrônico Básico para o Português do Brasil) de Dias-da-Silva; Morales (2003) e no léxico de sentimento de Hu; Liu (2004) traduzido para o português. A base de dados da OpenWordNet-PT (De Paiva; Rademaker; Melo, 2012) é o resultado da tradução da base de dados da WordNet de Princeton25, portanto, contém uma base de dados com grande abrangência, possui 62034 sentidos de pares de palavras e 45421 palavras únicas. A versão 2 do SentiLex (Silva; Carvalho; Sarmento, 2012) é composta por 82347 formas flexionadas, organizadas em adjetivos (16863), substantivos (1280), verbos (29504) e expressões idiomáticas (34700). O ReLi-Lex (Freitas, 2013) é derivado do corpus ReLi de Freitas et al. (2012), que é composto por resenhas de livros publicadas na internet e possui 1600 resenhas de treze livros (sete autores), este léxico contém 609 entradas. O WordNetAffect-BR (Pasqualotti, 2015) é um vocabulário de emoções que possui 289 palavras (adjetivos e substantivos). O Personalitatem Lexicon (Machado et al., 2015) contém lexemas de conotação afetiva baseada nos traços de personalidade e foi construído com base no Linguistic Inquiry e Word Count (LIWC) 2.015. O AffectPT-BR (Carvalho; Santos; Guedes, 2018) tem um total de 1.139 palavras atribuídas na categoria “afeto”, 479 em “posemo” e 661 em “negemo”. O LexReli (Machado; Pardo; Ruiz, 2018) é uma combinação de três léxicos, OpLexicon (Souza et al., 2011), SentiLex (Silva; Carvalho; Sarmento, 2012) e Brazilian Portuguese LIWC Dictionary (Balage Filho; Pardo; Aluísio, 2013), especializado em identificar a polaridade de aspectos em textos opinativos sobre livros e contém 1.543 entradas. O Brazilian Portuguese LIWC Dictionary (Balage Filho; Pardo; Aluísio, 2013) é um léxico disponível para a língua portuguesa, construído a partir do LIWC de Pennebaker; Francis; Booth (2001), ou seja, foi resultado de tradução automática, utilizando diversos dicionários bilíngues português-inglês e possui 127.149 instâncias.\n",
            "Virgula antes do ou: O OpLexicon (Souza et al., 2011) possui 30.322 palavras (23.433 adjetivos e 6.889 verbos) e foi construído com base em um corpus do português brasileiro (composto por 346 resenhas de filmes e 970 textos jornalísticos), no thesaurus denominado TEP (do português, Thesaurus Eletrônico Básico para o Português do Brasil) de Dias-da-Silva; Morales (2003) e no léxico de sentimento de Hu; Liu (2004) traduzido para o português. A base de dados da OpenWordNet-PT (De Paiva; Rademaker; Melo, 2012) é o resultado da tradução da base de dados da WordNet de Princeton25, portanto, contém uma base de dados com grande abrangência, possui 62034 sentidos de pares de palavras e 45421 palavras únicas. A versão 2 do SentiLex (Silva; Carvalho; Sarmento, 2012) é composta por 82347 formas flexionadas, organizadas em adjetivos (16863), substantivos (1280), verbos (29504) e expressões idiomáticas (34700). O ReLi-Lex (Freitas, 2013) é derivado do corpus ReLi de Freitas et al. (2012), que é composto por resenhas de livros publicadas na internet e possui 1600 resenhas de treze livros (sete autores), este léxico contém 609 entradas. O WordNetAffect-BR (Pasqualotti, 2015) é um vocabulário de emoções que possui 289 palavras (adjetivos e substantivos). O Personalitatem Lexicon (Machado et al., 2015) contém lexemas de conotação afetiva baseada nos traços de personalidade e foi construído com base no Linguistic Inquiry e Word Count (LIWC) 2.015. O AffectPT-BR (Carvalho; Santos; Guedes, 2018) tem um total de 1.139 palavras atribuídas na categoria “afeto”, 479 em “posemo” e 661 em “negemo”. O LexReli (Machado; Pardo; Ruiz, 2018) é uma combinação de três léxicos, OpLexicon (Souza et al., 2011), SentiLex (Silva; Carvalho; Sarmento, 2012) e Brazilian Portuguese LIWC Dictionary (Balage Filho; Pardo; Aluísio, 2013), especializado em identificar a polaridade de aspectos em textos opinativos sobre livros e contém 1.543 entradas. O Brazilian Portuguese LIWC Dictionary (Balage Filho; Pardo; Aluísio, 2013) é um léxico disponível para a língua portuguesa, construído a partir do LIWC de Pennebaker; Francis; Booth (2001), ou seja, foi resultado de tradução automática, utilizando diversos dicionários bilíngues português-inglês e possui 127.149 instâncias.\n",
            "Foram encontrados 3 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: No ano de 2022, foi proposto um desafio sobre AS no nível de aspecto (em inglês, Aspect-based Sentiment Analysis ou ABSA) para língua portuguesa no IberLEF26 denominado ABSAPT27. A proposta do ABSAPT foi inspirada em competições propostas em outros idiomas, como SemEval (Pontiki et al., 2014, 2015, 2016) para o inglês e EVALITA (Mattei et al., 2020) para o italiano. Além disso, tinha como público alvo acadêmicos, pesquisadores e profissionais de empresas privadas. Na competição participaram cinco equipes de diferentes universidades e institutos do Brasil. O corpora disponibilizado na competição foi desenvolvido por Freitas (2015) e Corrêa (2021). Os participantes usaram diferentes tipos de abordagens para resolver a tarefa de ABSA, a qual foi dividida em duas, identificação de aspectos e extração de polaridade destes aspectos. O time da UFSCAR (Assi et al., 2022) propôs uma solução baseada em regras e léxico de sentimento, os times do NILC (Machado; Pardo, 2022) e da UFPR (Heinrich; Marchi, 2022) propuseram soluções baseadas em AM, utilizando algoritmos de AM tradicionais como Conditional Random Field (CRF) e os times Deep Learning Brasil (Gomes et al., 2022), PiLN (Neto et al., 2022) e UFPR (Heinrich; Marchi, 2022) propuseram soluções baseada em AP, utilizando Transformers (Silva et al., 2022). Enfim, estratégias como estas, especialmente para línguas com poucos recursos como o português, são extremamente importantes.\n",
            "Foram encontrados 3 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: A detecção de notícias falsas, também conhecidas como fake news, em redes sociais é uma área de pesquisa crítica e desafiadora. A aplicação eficaz de técnicas de PLN nesse contexto é crucial para preservar a integridade da informação online e combater a desinformação, esta a qual pode ter consequências sérias tanto na política, quanto na economia, e ainda na sociedade como um todo. O PLN desempenha um papel fundamental no desenvolvimento de abordagens eficazes para lidar com esse problema. Apesar do problema de disseminação de notícias falsas estar presente em todas as redes sociais, algumas tendem a ter o compartilhamento deste tipo de conteúdo mais dissipado. De acordo com Cabral et al. (2021), o Whatsapp facilita a disseminação rápida de desinformação. No Brasil, cerca de 35% das notícias falsas são compartilhadas através do WhatsApp (Newman et al., 2020), e 40,7% destes mensagens são compartilhadas após serem desmentidas (Resende et al., 2019).\n",
            "Virgula antes do e: A detecção de notícias falsas, também conhecidas como fake news, em redes sociais é uma área de pesquisa crítica e desafiadora. A aplicação eficaz de técnicas de PLN nesse contexto é crucial para preservar a integridade da informação online e combater a desinformação, esta a qual pode ter consequências sérias tanto na política, quanto na economia, e ainda na sociedade como um todo. O PLN desempenha um papel fundamental no desenvolvimento de abordagens eficazes para lidar com esse problema. Apesar do problema de disseminação de notícias falsas estar presente em todas as redes sociais, algumas tendem a ter o compartilhamento deste tipo de conteúdo mais dissipado. De acordo com Cabral et al. (2021), o Whatsapp facilita a disseminação rápida de desinformação. No Brasil, cerca de 35% das notícias falsas são compartilhadas através do WhatsApp (Newman et al., 2020), e 40,7% destes mensagens são compartilhadas após serem desmentidas (Resende et al., 2019).\n",
            "Foram encontrados 5 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Na literatura, encontramos alguns corpora, descritos na língua portuguesa, anotados para a tarefa de detecção de notícias falsas em língua portuguesa, são eles: COVID-1932, FakeTweetBr33 de Cordeiro; Pinheiro (2019), Fake.br-Corpus34 de (Monteiro et al., 2018) e FakeWhatsApp35 de Cunha (2021). O COVID-19 contém notícias sobre a cura da COVID-19 postadas no Twitter/X. O FakeTweetBr é um corpus de notícias falsas também advindo do Twitter/X. O Fake.br-Corpus contém notícias classificadas em seis grandes categorias (política, TV e celebridades, sociedade e notícias diárias, ciência e tecnologia, economia, religião) extraídas do G136, Folha de São Paulo37 e Estadão38. O FakeWhatsApp possui mensagens anônimas do WhatsApp de grupos públicos do português brasileiro para detecção automática de desinformação textual e de usuários maliciosos.\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: Um dos trabalhos recentes que utiliza Aprendizado Profundo (AP) na detecção de notícias falsas é o trabalho de Narde (2021). Nele foram utilizados diferentes modelos (ELECTRA de Clark et al. (2020), RoBERTa de Liu et al. (2021), XLM-R de Conneau et al. (2020), Multilingual BERT de Devlin et al. (2019) e BERTimbau de Souza; Nogueira; Lotufo (2020)) para detectar notícias falsas em redes sociais. O modelo BERTimbau (Souza; Nogueira; Lotufo, 2020) com 6 épocas foi o que obteve acurácia e medida-F superior a todos outros os modelos utilizados nos experimentos, medida-F de 95%.\n",
            "Foram encontrados 6 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: No ano de 2021, foi proposto um desafio sobre detecção de ironia para língua portuguesa no IberLEF39 denominado IDPT40. A proposta do IDPT foi inspirada em competições proposta em outros idiomas, como SemEval (Hee; Lefever; Hoste, 2018) para o inglês, IronITA (Cignarella et al., 2018) para o italiano, IroSvA (Bueno et al., 2019) para o espanhol e IDAT (Ghanem et al., 2019) para o árabe. Participaram da tarefa seis equipes de universidades e de empresas de quatro diferentes países: Brasil, China, Portugal e Espanha. Os corpora disponibilizados na competição contêm textos (tweets e notícias) sobre diferentes temas. O conjunto de dados de treinamento foi desenvolvido por Freitas et al. (2014), Silva (2018) e Schubert; Freitas (2020). Os participantes usaram abordagens tradicionais de AM (como: SVM, NB e outros) e/ou AP (como: Transformers). Os times que atingiram os melhores resultados foram o BERT4EVER (Jiang et al., 2021) e PiLN (Anchiêta et al., 2021). BERT4EVER (Jiang et al., 2021) utilizou Transformers e obteve uma acurácia balanceada de 92% para conjunto de dados de notícias. Para o conjunto de dados composto por tweets, a equipe PiLN (Anchiêta et al., 2021) utilizou superficial features e SVM e obteve uma acurácia balanceada de 52%.\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Virgula antes do e: Falar sobre aplicações de PLN em redes sociais é de grande importância por diversas razões. As redes sociais desempenham um papel fundamental na comunicação e interação social na sociedade moderna. Compreender como o PLN é aplicado nessas plataformas é essencial para entender as dinâmicas sociais e o impacto da tecnologia na vida das pessoas. Este capítulo forneceu uma visão geral sobre aplicações de abordagens de PLN em conteúdos de redes sociais. Demos ênfase ao desenvolvimento de pesquisas desenvolvidas com foco na língua portuguesa, dado o foco deste livro e de esta ser ainda uma língua com recursos escassos para algumas tarefas. Nessa primeira versão, deixamos de cobrir tópicos relevantes e atuais como reconhecimento/classificação de emoções, rastreio de transtorno mental, e detecção de postura. Reconhecendo a importância destes tópicos, pretendemos contemplá-los na versão seguinte deste livro.\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: https://github.com/franciellevargas/HateBR↩︎\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: https://github.com/DougTrajano/olid-br↩︎\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: https://github.com/LaCAfe/Dataset-Hatespeech↩︎\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: https://github.com/own-pt/openWordnet-PT↩︎\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: https://www.linguateca.pt/Repositorio/ReLi/↩︎\n",
            "Foram encontrados 2 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: https://github.com/LaCAfe/AffectPT-br↩︎\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: https://github.com/prc992/FakeTweet.Br↩︎\n",
            "Foram encontrados 1 erros no seguinte parágrafo:\n",
            "Letras maiusculas no meio de palavras: https://github.com/cabrau/FakeWhatsApp.Br↩︎\n",
            "\n",
            "\n",
            "Foram encontrados 76 erros neste capítulo!\n"
          ]
        }
      ]
    }
  ]
}